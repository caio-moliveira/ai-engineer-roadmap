# üèóÔ∏è M√≥dulo 1: Fundamentos de RAG & Modelos Mentais

> **Goal:** Entender por que n√£o apenas "Fine-Tunamos" tudo.  
> **Status:** Arquitetura 101.

## 1. O que √© RAG? (Realmente)
RAG √© uma **Prova com Consulta** para IA.
- **Fine-Tuning:** Estudar para a prova e tentar decorar o livro (Livro Fechado).
- **RAG:** Levar o livro para a prova e consultar a resposta (Livro Aberto).

### Por que LLMs sozinhos falham
LLMs s√£o **Motores de Racioc√≠nio**, n√£o Bancos de Dados de Conhecimento.
- Eles t√™m um "Knowledge Cutoff" (data de corte).
- Eles alucinam fatos obscuros.
- Eles n√£o t√™m acesso aos dados privados da sua empresa (SQL/Notion/Slack).

## 2. RAG vs Fine-Tuning
Este √© o t√≥pico #1 de confus√£o.

| Feature | RAG | Fine-Tuning |
|:---|:---|:---|
| **Objetivo** | Adicionar conhecimento novo. | Mudar comportamento/estilo. |
| **Acur√°cia** | Alta (fundamentada em docs). | Vari√°vel (risco de alucina√ß√£o). |
| **Velocidade de Update** | Instant√¢nea (add doc no DB). | Lenta (re-treinar modelo). |
| **Rastreabilidade** | Perfeita (cita fontes). | Zero (caixa preta). |
| **Custo** | Baixo (Vector DB). | Alto (GPU compute). |

> **Regra:** Sempre tente RAG primeiro. Fine-tune apenas se precisar que o modelo fale uma linguagem muito espec√≠fica (ex: Alem√£o M√©dico) ou gere um formato complexo (SQL) consistentemente.

## 3. A Evolu√ß√£o do RAG
Estamos atualmente na Gera√ß√£o 3.

### Gen 1: Naive RAG (2023)
- Processo: PDF -> Dividir a cada 500 chars -> Embed -> Retornar top 4 -> Jogar no Prompt.
- Resultado: "N√£o sei" ou respostas erradas porque o contexto foi perdido.

### Gen 2: Advanced RAG (2024)
- **Hybrid Search:** Keywords + Vetores.
- **Reranking:** Usar um Cross-Encoder para filtrar resultados ruins.
- **Re-writing:** Transformar "Quanto custa?" em "Quanto custa o iPhone 15 Pro?".

### Gen 3: Agentic RAG (2025)
- **Tool Use:** O LLM decide *se* precisa pesquisar.
- **Multi-Step:** Pesquisa -> L√™ -> Pesquisa de novo.
- **Racioc√≠nio:** "Achei X, mas contradiz Y. Preciso checar Z."

## 4. Arquitetura Moderna (O Stack Padr√£o)
1.  **Ingestion Service:** Dados n√£o estruturados -> Limpeza -> Armazenamento.
2.  **Vector Store (Qdrant):** Mem√≥ria de longo prazo.
3.  **Retriever:** A l√≥gica que encontra dados (Bm25 + Dense).
4.  **Generator:** O LLM que sintetiza a resposta.

## üß† Mental Model: "O Bibliotec√°rio"
Imagine um Bibliotec√°rio (O Retriever) e um Professor (O LLM).
- Voc√™ faz uma pergunta ao Professor.
- O Professor pede ao Bibliotec√°rio para achar os livros.
- O Bibliotec√°rio traz 5 p√°ginas.
- O Professor l√™ e te responde.

**Se o Bibliotec√°rio trouxer as p√°ginas erradas, o Professor n√£o consegue responder.**
**Falha no RAG √© quase sempre falha de Retrieval.**

## ‚è≠Ô∏è Pr√≥ximo Passo
Vamos ver como organizar os livros.
V√° para **[M√≥dulo 2: Ingest√£o de Dados e Pipelines](../02-ingestion-pipeline)**.
