# M√≥dulo 06: Agentes RAG (RAG Agents)

Este m√≥dulo avan√ßa do conceito de **RAG Pipelines** (sequ√™ncias lineares de recupera√ß√£o + gera√ß√£o) para **RAG Agents** (sistemas aut√¥nomos que usam razocin√≠o para decidir *quando* e *o qu√™* buscar).

Enquanto um pipeline tradicional faz "Retrieval -> Generation" sempre, um Agente pode:
1.  Receber uma pergunta complexa.
2.  Decidir que precisa buscar informa√ß√µes no banco vetorial.
3.  Formular a query de busca (que pode ser diferente da pergunta do usu√°rio).
4.  Analisar os documentos retornados.
5.  Se a informa√ß√£o for insuficiente, realizar uma nova busca ou responder que n√£o sabe.

## üìÇ Estrutura dos Arquivos

### üõ†Ô∏è Utilit√°rios

- **`utils.py`**:
  - Script compartilhado que gerencia a conex√£o com o **Qdrant** e indexa o PDF `Understanding_Climate_Change.pdf` (localizado em `02-rag/05-retrievers/`).
  - Garante que a collection `climate_change_collection` exista.

### ü¶ú Agente com LangChain (LangGraph)

- **Arquivo**: `01_rag_agent_langchain.py`
- **Framework**: Usa componentes modernos do **LangGraph** (a evolu√ß√£o dos agentes no LangChain).
- **Tooling**:
  - Define uma *Custom Tool* usando o decorador `@tool`.
  - A ferramenta `retrieve_context` acessa o Qdrant para buscar chunks relevantes.
- **Arquitetura**: **ReAct (Reasoning + Acting)**. O modelo (GPT-4o) recebe a descri√ß√£o da ferramenta e decide cham√°-la se a pergunta do usu√°rio exigir contexto externo.
- **Destaque**: Uso de `.stream()` com `stream_mode="values"` para visualizar o processo de racioc√≠nio passo-a-passo.
- **Docs**:
  - [LangChain RAG-Agent](https://docs.langchain.com/oss/python/langchain/rag#rag-chains)
  - [LangGraph RAG-Agent](https://docs.langchain.com/oss/python/langgraph/agentic-rag)

### ü¶ô Agente com LlamaIndex

- **Arquivo**: `02_rag_agent_llamaindex.py`
- **Framework**: **LlamaIndex Agents**.
- **Tooling**:
  - Usa `QueryEngineTool`. O LlamaIndex encapsula todo o pipeline de busca (Index -> Retriever -> Response Synthesizer) em uma √∫nica ferramenta.
  - O agente enxerga essa ferramenta como uma "API" para consultar sua base de conhecimento.
- **Arquitetura**: **Function Calling Agent**. Otimizado para LLMs que suportam chamada de fun√ß√£o nativa (como GPT-3.5/4o), permitindo chamadas de ferramentas mais robustas e estruturadas.
- **Destaque**: A facilidade de conectar o `VectorStoreIndex` diretamente como uma ferramenta para o agente.
- **Docs**:
  - [LlamaIndex Agents](https://docs.llamaindex.ai/en/stable/module_guides/deploying/agents/)


### Executando os Agentes

```bash
# Vers√£o LangChain
python 02-rag/06-rag-agent/01_rag_agent_langchain.py

# Vers√£o LlamaIndex
python 02-rag/06-rag-agent/02_rag_agent_llamaindex.py
```

## üß† Pipeline vs Agente: Qual escolher?

| Caracter√≠stica | RAG Pipeline (Chain) | RAG Agent |
| :--- | :--- | :--- |
| **Fluxo** | Linear (Retrieval -> Generate) | Din√¢mico (ReAct, Loop) |
| **Previsibilidade** | Alta (Sempre faz a mesma coisa) | M√©dia (O modelo decide o caminho) |
| **Custo** | Baixo (1 chamada LLM geralmente) | M√©dio/Alto (M√∫ltiplas chamadas/loops) |
| **Complexidade** | Simples | Alta |
| **Uso Ideal** | Perguntas diretas ("O que √© X?") | Perguntas multi-step ("Compare X com Y e resuma") |
