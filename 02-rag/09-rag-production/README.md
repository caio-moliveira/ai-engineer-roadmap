# ğŸš€ MÃ³dulo 10: RAG em ProduÃ§Ã£o

> **Goal:** 99.9% Uptime. <2s LatÃªncia. Custo Baixo.  
> **Status:** A linha de chegada.

## 1. OtimizaÃ§Ã£o de LatÃªncia
UsuÃ¡rios odeiam esperar.
- **O Gargalo:** Geralmente Ã© a GeraÃ§Ã£o do LLM.
- **O Fix:** Streaming (SSE). Mostre o primeiro token imediatamente.
- **OtimizaÃ§Ã£o de Retrieval:** Saia do Python `faiss` para Qdrant (Rust/C++).
- **Reranking:** Limite o reranking aos top 10 docs, nÃ£o top 100.

## 2. Caching (O Cache SemÃ¢ntico)
Por que pagar pela mesma pergunta duas vezes?
- **Match Exato:** Redis. Se `query == "preÃ§os"`, retorna resposta cacheada.
- **Cache SemÃ¢ntico:** GPTCache. Se `query â‰ˆ "quanto custa"`, retorna resposta cacheada para "preÃ§os".
- **Impacto:** Reduz custo em 30-50% e latÃªncia para 0ms.

## 3. EstratÃ©gia de Contexto Vazio
O que acontece se o Retriever nÃ£o retornar nada?
- **Ruim:** LLM diz "Baseado no contexto [VAZIO]...".
- **Bom:** LÃ³gica de Fallback.
    - "NÃ£o encontrei isso nos documentos."
    - "Buscando no Google..." (Fallback AgÃªntico).

## 4. SeguranÃ§a (ACLs)
**O Problema do "SalÃ¡rio do CEO".**
- UsuÃ¡rio A (EstagiÃ¡rio) pergunta "Qual o salÃ¡rio do CEO?".
- Vector DB acha o doc "FolhaPagamento2024.pdf".
- LLM responde.
- **Resultado:** Vazamento de Dados.

**Fix:** Filtragem de Metadados.
```python
filters = Filter(
    must=[
        FieldCondition(key="access_level", match=MatchValue(value="public"))
    ]
)
```

## 5. Controle de Custo
- **Limites de Token:** NÃ£o deixe usuÃ¡rios colarem 100k palavras. Trunque o input.
- **Model Routing:** Use Haiku/GPT-4o-mini para queries simples. Use Opus/GPT-4o para complexas.

## ğŸ§± Checklist de ProduÃ§Ã£o
Antes de shippar o Bloco 2:
- [ ] Seus chunks tÃªm overlap?
- [ ] A extraÃ§Ã£o de metadados estÃ¡ funcionando?
- [ ] VocÃª estÃ¡ usando Hybrid Search?
- [ ] VocÃª tem um Reranker?
- [ ] Streaming estÃ¡ ativado?
- [ ] AvaliaÃ§Ã£o com Ragas estÃ¡ rodando?
- [ ] VocÃª trata Contexto Vazio?
- [ ] PermissÃµes (ACLs) estÃ£o aplicadas?

## ğŸ“ GraduaÃ§Ã£o
VocÃª completou o Bloco 2.
VocÃª entende **Retrieval Augmented Generation** profundamente.

**PrÃ³ximo Bloco: [AI Agents](../../03-ai-agents)**
