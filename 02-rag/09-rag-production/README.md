# Agentic RAG com Qdrant & LangGraph (Produ√ß√£o)

Este m√≥dulo representa o projeto final da nossa trilha de *Retrieval-Augmented Generation* (RAG). Aqui, elevamos o sistema RAG tradicional para uma arquitetura **Agentic RAG**, pronta para produ√ß√£o, que une a for√ßa de bancos de dados vetoriais locais (Qdrant), frameworks de agentes (LangGraph e LangChain), e uma API moderna (FastAPI).

## üéØ Objetivo Arquitetural

No RAG Tradicional, o fluxo √© fixo: o usu√°rio pergunta, o sistema sempre busca no banco de dados vetorial, anexa o contexto e envia ao LLM.

**No nosso projeto (Agentic RAG):** 
N√≥s utilizamos o **LangGraph** para criar um Agente (LLM) que toma decis√µes. Atrav√©s de *Tools* (ferramentas), o modelo decide proativamente:
1. **Devo responder diretamente?** (Para bate-papo, sauda√ß√µes "Ol√°, bom dia").
2. **Devo invocar a ferramenta de busca?** (Para perguntas t√©cnicas ou sobre o acervo documental).

Isso resulta em um sistema mais inteligente, que n√£o gasta tokens e tempo fazendo buscas desnecess√°rias, mas realiza *queries* cir√∫rgicas na base vetorial quando precisada de contexto.

## üõ†Ô∏è Stack Tecnol√≥gica e Ferramentas

O ecossistema que constru√≠mos envolve as seguintes tecnologias:

*   **FastAPI**: Servidor web ass√≠ncrono hiper-r√°pido, provendo os endpoints da nossa aplica√ß√£o Restful.
*   **Qdrant**: Nosso Banco de Dados Vetorial *Open Source*. Estamos rodando o Qdrant via Docker localmente (porta 6333) para persistir nossos embeddings de alta dimens√£o.
*   **LangChain & LangGraph**: Orquestra√ß√£o do agente. O `LangGraph` gerencia o Estado da nossa conversa (StateGraph) e o ciclo din√¢mico cont√≠nuo entre invoca√ß√µes diretas ao LLM e o *ToolNode* (nossa ferramenta de busca).
*   **OpenAI Embeddings (text-embedding-3-large)**: Cria√ß√£o de vetores para mapeamento sem√¢ntico dos textos.
*   **OpenAI LLM (gpt-4o-mini)**: O "C√©rebro" do Agente, encarregado de interpretar requests e executar chamadas da ferramenta de retrieve.
*   **Langfuse**: Plataforma de Observabilidade e Monitoramento de LLMs. Usado atrav√©s de callbacks para tra√ßar e analisar cada token gerado e tempo de infer√™ncia nas requisi√ß√µes.

## üóÇÔ∏è Estrutura do Projeto

```text
09-rag-production/
‚îú‚îÄ‚îÄ index.html                  # Interface Web Frontend simples para testes (Chat + Upload).
‚îú‚îÄ‚îÄ main.py                     # Entrypoint do Uvicorn que sobe a aplica√ß√£o FastAPI.
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ api.py                  # Defini√ß√£o do FastAPI, CORS e inclus√£o de Routers.
‚îÇ   ‚îú‚îÄ‚îÄ models.py               # Contratos de dados (Pydantic Models) para as Requisi√ß√µes/Respostas.
‚îÇ   ‚îú‚îÄ‚îÄ settings.py             # Gerenciamento de Vari√°veis de Ambiente e chaves de API.
‚îÇ   ‚îú‚îÄ‚îÄ pdf_utils.py            # Utilit√°rios de extra√ß√£o de texto em mem√≥ria (PyMuPDF - fitz).
‚îÇ   ‚îú‚îÄ‚îÄ customlogger.py         # Configura√ß√£o de Logs padronizado para console.
‚îÇ   ‚îú‚îÄ‚îÄ chat/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chat.py             # Core do Agentic RAG: Graph State, Agente LLM, e a Tool de Retrieve.
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ llm_models.py       # Instancia√ß√£o centralizada das LLMs e Embeddings conectados ao Langfuse.
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ qdrant.py           # Conex√£o AsyncGlobal com o servi√ßo Qdrant.
‚îÇ   ‚îú‚îÄ‚îÄ embedder/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ client.py           # Opera√ß√µes de Banco (Criar collection, Upsert Vetores).
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ processor.py        # Processamento Inteligente: Chunking Din√¢mico, Extra√ß√£o Meta-Info + LLM.
‚îÇ   ‚îî‚îÄ‚îÄ routers/
‚îÇ       ‚îú‚îÄ‚îÄ chat.py             # Endpoint /chat/ask -> Conecta o cliente Frontend ao agente.
‚îÇ       ‚îú‚îÄ‚îÄ embedder.py         # Endpoints de Upload, Processamento e Cole√ß√µes.
‚îÇ       ‚îî‚îÄ‚îÄ qdrant.py           # (Antigo/Legado) Rotas adicionais de administra√ß√£o CRUD do Qdrant.
```

## ‚öôÔ∏è Novidades e Funcionalidades Core

### 1. Ingest√£o Din√¢mica de Documentos
Foi criado um motor flex√≠vel no `processor.py` para ingest√£o:
*   Os administradores podem atrav√©s de Endpoints subir PDFs diretamente para *Collections* espec√≠ficas.
*   Pode ser decidido em tempo-de-requisi√ß√£o se usaremos divisores Recursivos (`RecursiveCharacterTextSplitter`) ou por blocos fechados.
*   Tamanho de Chunks, Overlap e tokenizadores locais (`tiktoken`) s√£o parametrizados via API dinamicamente.

### 2. Auto-Extra√ß√£o de Metadados via LLM
Ao enviar um documento para o vetor, o sistema l√™ automaticamente a primeira p√°gina e solicita dinamicamente a outro LLM (via `with_structured_output`) que emita:
*   `classificacao`: Qual o tipo do arquivo em 3 palavras.
*   `descricao`: Resumo funcional em 2 frases.
* Isso entra como metadados enriquecidos no banco, facilitando filtros e aumentando contexto de leitura futura.

### 3. Agente com Tool Calling e Multi-Collections
O chat mudou radicalmente nesta vers√£o. Usamos a magia do `StateGraph` do LangGraph.
*   O estado gerencia a lista de mensagens (`messages`) e tamb√©m o arquivo contextual (`file_context`).
*   O Endpoints aceita no payload `collection_name`, passando dinamicamente essa vari√°vel na configura√ß√£o de Runtime do LangGraph para a ferramenta `retrieve_documents`. Assim o usu√°rio pesquisa na base que quiser sem reescrever c√≥digo.
*   **O Agente pensa:** Se a requisi√ß√£o requerer, o agente ativa a *tool*, varre o banco, junta o resultado retornado pela Tool, formata com cita√ß√µes ("Fonte: arquivo X, p√°g Y") e molda a resposta final.

### 4. Observabilidade Real (Langfuse)
As chamadas da Rota `/chat/ask` instanciam um `CallbackHandler()` do Langfuse especificamente e dinamicamente para aquela requisi√ß√£o, rotulando com Tags o nome da cole√ß√£o acessada e atrelando tudo a `session_id`'s independentes.


## üöÄ Como Executar Localmente

### Pr√©-requisitos
1.  **Docker**: Necess√°rio para rodar o Qdrant local.
2.  **uv** (ou pip): Gerenciador de depend√™ncias python moderno.
3.  **Ambiente configurado**: Crie um arquivo `.env` na raiz da pasta `09-rag-production` baseado nas chaves pedidas. (OpenAI API e Langfuse)

### Passos:

1.  **Subir o Qdrant pelo Docker:**
    ```bash
    docker run -p 6333:6333 -p 6334:6334 -v qdrant_data:/qdrant/storage:z qdrant/qdrant
    ```

2.  **Instalar e ativar ambiente virtual (se usando UV):**
    ```bash
    uv venv
    uv pip sync requirements.txt
    uv pip install pymupdf  # Garantir compatibilidade do processador PDF
    ```

3.  **Rodar a aplica√ß√£o FastAPI:**
    ```bash
    uv run uvicorn main:app --host 0.0.0.0 --port 8000 --reload
    ```

4.  **Testar via UI Pr√≥pria!**
    *   V√° no explorador de arquivos, ache o `index.html` deixado na raiz da pasta `09-rag-production`.
    *   D√™ um duplo-clique para abrir no Google Chrome / Edge.
    *   No painel esquerdo: Crie uma cole√ß√£o "base_estudo" e envie seus PDFs ou TXTs.
    *   No painel direito: Troque o campo "Cole√ß√£o" para "base_estudo" e interaja com o agente em tempo real!
