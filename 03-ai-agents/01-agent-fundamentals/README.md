# ü§ñ M√≥dulo 1: Fundamentos de Agentes e Arquiteturas

> **Objetivo do m√≥dulo:** estabelecer uma defini√ß√£o operacional de ‚Äúagente‚Äù e o que muda na engenharia do sistema quando um LLM passa a **controlar o fluxo** via **tools** e **loops**, e explorar os Padr√µes de Design para Racioc√≠nio (Arquiteturas).  
> **Pr√©-requisito:** conceitos b√°sicos de LLM, prompt, RAG/workflows, APIs.

---

## 1) Defini√ß√£o operacional: o que √© um Agente?

Em Engenharia de Software, ‚Äúagente‚Äù n√£o √© um personagem aut√¥nomo ‚Äî √© uma **arquitetura**.

**Defini√ß√£o (pr√°tica):**  
Um **Agente de IA** √© um sistema em que um **LLM atua como policy/controller**, decidindo **qual a√ß√£o executar a seguir** (ou se deve responder), com base em estado, objetivos e observa√ß√µes do ambiente.

Na pr√°tica, isso significa:

- O LLM n√£o √© s√≥ ‚Äúgerador de texto‚Äù ‚Üí ele √© o **componente que escolhe passos**.
- O sistema possui **a√ß√µes externas** (tools) que alteram o mundo: buscar, chamar APIs, executar c√≥digo, editar arquivos, consultar banco, etc.
- A execu√ß√£o ocorre em um **loop controlado** (com guardrails).

> **Atalho mental:** agente = **LLM (controlador) + Tools (a√ß√µes) + Loop (controle)**

---

## 2) Agente vs. Workflow (ex.: RAG)

A diferen√ßa central n√£o √© ‚Äúusar LLM‚Äù, e sim **quem controla o fluxo**.

### 2.1 Workflow (RAG / pipeline determin√≠stico)
Fluxo **hardcoded**: voc√™ define a sequ√™ncia e o LLM s√≥ ‚Äúpreenche‚Äù o texto.

Exemplo t√≠pico:
`Input ‚Üí Retrieval ‚Üí (Contexto) ‚Üí LLM ‚Üí Output`

Caracter√≠sticas:
- Controle previs√≠vel (bom para produ√ß√£o)
- Falhas mais f√°ceis de reproduzir
- Menos flex√≠vel quando h√° muitas rotas/decis√µes

### 2.2 Agente (controle pelo modelo)
Fluxo **decidido dinamicamente**: o LLM escolhe *o que fazer agora*.

Exemplo t√≠pico:
`Input ‚Üí LLM decide ‚Üí Tool ‚Üí Observa√ß√£o ‚Üí LLM decide ‚Üí ‚Ä¶ ‚Üí Output`

Caracter√≠sticas:
- Flexibilidade para tarefas multi-etapas e interativas
- Maior risco operacional (loops, custos, instabilidade)
- Exige engenharia de **controle, observabilidade e avalia√ß√£o**

---

## 3) O ‚Äúspectrum‚Äù de autonomia (por que isso importa)

Nem todo ‚Äúagente‚Äù precisa ser aut√¥nomo. Em produ√ß√£o, autonomia √© uma **vari√°vel de risco**.

1. **Router (baixa autonomia / baixo risco)**  
   - Decide entre caminhos conhecidos (A/B/N).  
   - √ötil para roteamento: ‚ÄúRAG vs SQL vs FAQ‚Äù.

2. **State Machine / Graph (autonomia moderada / risco moderado)**  
   - O fluxo √© um **grafo expl√≠cito**, mas o modelo decide **transi√ß√µes** e **loops**.  
   - Aqui entra muito bem o **LangGraph**: voc√™ define n√≥s/arestas/estado e coloca limites.

3. **Fully Autonomous (alta autonomia / alto risco)**  
   - Planeja, executa, replaneja, cria subtarefas e decide tudo.  
   - Bom para prot√≥tipo/pesquisa; dif√≠cil de estabilizar sem muita instrumenta√ß√£o.

**Regra de ouro (engenharia):** d√™ o **m√≠nimo** de autonomia que resolve o problema.  
Autonomia aumenta: **custo (tokens), vari√¢ncia, risco e dificuldade de QA**.

---

## 4) A virada ‚ÄúLLM + Tools‚Äù (2022‚Äì2024): como ‚Äúagentes‚Äù se consolidaram

Essa fase marca quando o mercado percebe que ‚Äúagente‚Äù n√£o √© s√≥ prompt ‚Äî √© **LLM como controlador + ferramentas externas**.

### Marcos conceituais (o que cada um adiciona ao design)
- **MRKL (2022):** blueprint neuro-simb√≥lico modular ‚Üí LLM orquestra m√≥dulos externos (conhecimento, ferramentas, racioc√≠nio discreto).  
  **Impacto:** arquitetura modular e roteamento expl√≠cito.

- **ReAct (2022/2023):** padr√£o *Reasoning + Acting* ‚Üí alterna racioc√≠nio e a√ß√µes (consultas, APIs).  
  **Impacto:** reduz alucina√ß√£o e melhora tarefas interativas (via observa√ß√£o).

- **Toolformer (2023):** mostra aprendizado (supervisionado/auto-gerado) de **quando** chamar tools e **como** incorporar respostas.  
  **Impacto:** ‚Äútool use‚Äù deixa de ser artesanal.

- **Reflexion (2023):** melhora iterativa sem fine-tuning usando **feedback em linguagem** e ‚Äúmem√≥ria epis√≥dica‚Äù.  
  **Impacto:** introduz o loop ‚Äútentar ‚Üí refletir ‚Üí tentar melhor‚Äù com mem√≥ria.

- **AutoGPT / wave open-source (2023):** populariza autonomia e loops (planejar ‚Üí executar ‚Üí avaliar), mas exp√µe riscos:  
  **loops infinitos**, custo alto, instabilidade, tool errors.

**Conclus√£o dessa fase:** agente = **loop + tools + decis√µes**, e n√£o um ‚Äúprompt m√°gico‚Äù.

---

## 5) Agentes hoje (2024‚Äì2026): menos hype, mais engenharia

A tend√™ncia recente √© mover do ‚Äúaut√¥nomo por aut√¥nomo‚Äù para **agentic systems controlados**:

- **Interfaces de a√ß√£o bem definidas**
- **Observabilidade**
- **Avalia√ß√£o/benchmarks**
- **Guardrails e limites operacionais**

### Exemplo de tese importante: Agent-Computer Interface (ACI)
Sistemas como **SWE-agent (2024)** colocam foco no ‚Äúcomo o agente opera o ambiente‚Äù:
- navegar reposit√≥rios
- editar arquivos
- rodar testes
- abrir PRs

**Tese:** a interface (ACI) muda performance tanto quanto o modelo/prompt.

---

## 6) Componentes de um agente ‚Äúde verdade‚Äù (arquitetura m√≠nima em produ√ß√£o)

Um agente robusto geralmente separa responsabilidades:

### 6.1 Planejamento e roteamento
- decomposi√ß√£o (subtarefas)
- sele√ß√£o de estrat√©gia
- roteamento para ferramentas / especialistas

### 6.2 Tool use (a√ß√µes)
- ferramentas com contratos est√°veis (schema, erros, timeouts)
- valida√ß√£o de entradas/sa√≠das (tipagem / JSON schema)
- retries controlados

### 6.3 Mem√≥ria (quando faz sentido)
- **curto prazo** (estado da execu√ß√£o)
- **epis√≥dica** (tentativas, falhas, reflex√µes)
- **vetorial** (conhecimento recuper√°vel)

### 6.4 Controle e seguran√ßa (guardrails)
- limites de itera√ß√£o
- or√ßamento de tokens/custo
- timeouts
- valida√ß√£o de output (ex.: checagens, testes, regras)
- pol√≠ticas de acesso a tools (allowlist)

> **Checklist de produ√ß√£o:** Sem guardrails + observabilidade, ‚Äúagente‚Äù vira demo inst√°vel.

---

## 7) Por que agentes falham em produ√ß√£o (e como pensar como engenheiro)

Falhas comuns:

1. **Loops infinitos / thrashing**  
   - repete a mesma ferramenta/estrat√©gia sem convergir  
   ‚Üí mitigar com limites, detec√ß√£o de repeti√ß√£o, pol√≠ticas de fallback.

2. **Tools fr√°geis / contratos inconsistentes**  
   - API retorna 500, muda payload, n√£o tem timeout  
   ‚Üí mitigar com wrappers, schemas, versionamento, testes, circuit breaker.

3. **Estado/mem√≥ria mal projetados**  
   - o agente ‚Äúesquece‚Äù, contradiz, perde contexto operacional  
   ‚Üí mitigar com state expl√≠cito (ex.: LangGraph), mem√≥ria epis√≥dica √∫til, e logs.

---

## üß† Mental model: ‚Äúo estagi√°rio inteligente (com API access)‚Äù
Trate o agente como algu√©m competente, mas sem contexto e sem bom senso por padr√£o:
- Sem instru√ß√µes e ferramentas claras ‚Üí decis√µes ruins
- Com contratos claros + limites + observabilidade ‚Üí excelente executor

---

## 8) Arquiteturas de Agentes (Padr√µes de Design para Racioc√≠nio)

### 8.1 ReAct (Reason + Act)
O padr√£o cl√°ssico (2023).
- **Loop:**
  1. **Thought:** "O usu√°rio pediu o clima em SP."
  2. **Action:** `get_weather("Sao Paulo")`
  3. **Observation:** "25 graus, encoberto."
  4. **Thought:** "Tenho a resposta."
  5. **Answer:** "Est√° 25 graus."
- **Problema:** Simples demais. Se falhar, tendencia a alucinar.

### 8.2 Plan-and-Solve (Planner)
Para tarefas complexas ("Crie um app React").
- **Passo 1 (Planner):** O agente quebra o problema em steps.
- **Passo 2 (Executor):** Outro agente executa cada passo da lista.
- **Vantagem:** Menos perda de contexto. Foco em uma tarefa por vez.

### 8.3 Reflection (Self-Correction)
O segredo da alta performance.
- O agente gera um output.
- O agente **Critica** o pr√≥prio output ("Isso est√° correto? Falta algo?").
- O agente **Refina** a resposta.
> **Dica de Produ√ß√£o:** Adicionar um passo de Reflex√£o melhora a precis√£o em ~30%, mas dobra o custo.

### 8.4 Tool-Augmented RAG
A arquitetura mais comum em empresas.
- O Agente tem acesso a uma Tool de `Retriever`.
- Ele decide *quando* pesquisar no Vector DB.
- Diferente do RAG tradicional, ele pode pesquisar m√∫ltiplas vezes ou refinar a busca.

## üß† Mental Model Expandido: "System 1 vs System 2"
- **LLM Padr√£o (Chat):** System 1 (R√°pido, Intuitivo, Propenso a Erro).
- **Agente com Reflex√£o:** System 2 (Lento, Deliberativo, Preciso).

Use arquiteturas complexas apenas quando System 1 n√£o for suficiente.

---

## ‚è≠Ô∏è Pr√≥ximo passo
**Criando seu primeiro Agente:** Tool Calling, Structured Output e Controle usando LangChain.  
Ir para: `../02-my-first-agent`