# ü§ñ M√≥dulo 06: Fundamentos de LLMs & GenAI

> **Goal:** Entender a mat√©ria-prima da nova computa√ß√£o.
> **Ferramentas:** `OpenAI API`, `Anthropic`, `LangChain` (Conceitos).

## 1. Tokeniza√ß√£o: A Unidade At√¥mica
N√£o processamos palavras, processamos tokens.
- Entenda por que `"9.11"` pode ser maior que `"9.9"`.
- Token Limits: Context Window n√£o √© infinita.
- Custo: Voc√™ paga por **Input** (barato) e **Output** (caro).

## 2. O Ciclo de Vida do Prompt
Prompt Engineering n√£o √© "pedir com educa√ß√£o". √â estruturar contexto.
1.  **System Prompt:** Define a persona e regras imut√°veis.
2.  **Few-Shot:** Exemplos ensinam mais que instru√ß√µes.
3.  **User Prompt:** A query din√¢mica.

## 3. Tool Calling (Function Calling)
Aqui a m√°gica acontece. O LLM deixa de ser um chatbot e vira um **Agente**.
O modelo retorna um JSON estruturado pedindo para executar uma fun√ß√£o (`get_weather`, `query_sql`).
**Voc√™** executa o c√≥digo e devolve o resultado para ele.

*Frameworks:*
- Entenda como a OpenAI faz isso nativamente.
- Frameworks como `LangGraph` orquestram esses fluxos complexos de m√∫ltiplas ferramentas.

## 4. Structured Outputs (De novo)
Refor√ßando: Em produ√ß√£o, probabl√≠stico vira determin√≠stico.
Nunca fa√ßa parse de markdown/regex na sa√≠da do LLM. Use `json_mode` ou `Structured Outputs` para garantir JSON v√°lido.

## ‚è≠Ô∏è Pr√≥ximo Passo
O LLM sozinho n√£o sabe nada sobre *seus* dados privados. Vamos dar mem√≥ria a ele.
V√° para **[M√≥dulo 08: RAG (Retrieval-Augmented Generation)](../08-rag-fundamentals)**.
