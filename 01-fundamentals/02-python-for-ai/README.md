# üêç Python para Sistemas de IA: O Framework de Engenharia

> **Objetivo:** Estabelecer a funda√ß√£o t√©cnica para constru√ß√£o de sistemas de IA, indo al√©m de notebooks e scripts experimentais. Aqui, Python √© tratado como a infraestrutura de aplica√ß√µes cr√≠ticas.

Este m√≥dulo define como um AI Engineer S√™nior estrutura seu ambiente e escolhe suas ferramentas para construir LLMs, RAGs e Agentes em produ√ß√£o.

---

## üèóÔ∏è Parte 1: Setup do Workspace (N√≠vel AI Engineer)

Esque√ßa o tutorial b√°sico de `pip install`. Em sistemas complexos de IA, **reprodutibilidade e isolamento** s√£o inegoci√°veis. O caos de depend√™ncias √© o maior inimigo da estabilidade operacional.

### Por que o modelo tradicional falha?
O m√©todo antigo (`venv` + `requirements.txt` gerado manualmente ou com `pip freeze`) n√£o garante determinismo. Builds quebram porque bibliotecas "filhas" atualizaram sem aviso. Em IA, onde pacotes como `torch` ou `cuda` s√£o massivos e sens√≠veis, isso √© fatal.

### O Stack Moderno

#### **1. Gerenciamento de Depend√™ncias: `uv`**
O novo padr√£o industrial. Escrito em Rust, substitui `pip`, `poetry`, `pyenv` e `virtualenv` de uma s√≥ vez.
- **Lockfiles Universais:** Garante que a vers√£o exata (hash) instalada no seu laptop seja a mesma do container em produ√ß√£o.
- **Workspaces:** Suporte nativo a monorepos, permitindo ter m√∫ltiplos pacotes (ex: `core`, `api`, `workers`) compartilhando depend√™ncias base.
- **Velocidade:** Instala pacotes pesados de ML (GBs) em segundos, n√£o minutos.

#### **2. Estrutura de Projeto (Separation of Concerns)**
- **Dev/Test/Prod:** Separa√ß√£o r√≠gida de depend√™ncias via grupos no `pyproject.toml`.
- **Configura√ß√£o Centralizada:** Todas as ferramentas (`ruff`, `mypy`, `pytest`) leem do mesmo `pyproject.toml`. Nada de arquivos de config espalhados.

> **Mindset:** "Meu ambiente de desenvolvimento √© uma r√©plica determin√≠stica da produ√ß√£o. Se funciona aqui, o container sobe l√°."

---

## üõ†Ô∏è Parte 2: Bibliotecas Core para Sistemas de IA

Antes de falar de LLMs, precisamos de uma base s√≥lida de Engenharia de Software. Estas s√£o as ferramentas que sustentam o sistema.

| Biblioteca | Fun√ß√£o no Sistema de IA |
| :--- | :--- |
| **Pydantic** | **O Contrato de Dados.** Define a estrutura de inputs/outputs, valida respostas de LLMs e garante integridade. Essencial para *Structured Outputs*. |
| **FastAPI** | **A Camada de Servi√ßo.** Padr√£o para servir modelos e APIs de RAG devido ao suporte nativo a AsyncIO e inje√ß√£o de depend√™ncia. |
| **HTTPX** | **O Cliente Web.** O substituto moderno do `requests`. Totalmente ass√≠ncrono, perfeito para orquestrar chamadas paralelas a APIs de LLM. |
| **AsyncIO** | **A Concorr√™ncia.** LLMs s√£o lentos (I/O bound). AsyncIO permite processar milhares de requests enquanto aguarda a infer√™ncia. |
| **Tenacity** | **A Resili√™ncia.** Retries inteligentes com *exponential backoff*. Obrigat√≥rio, pois APIs de IA falham frequentemente. |
| **Logging** | **A Observabilidade.** Logs estruturados. Vital para rastrear o fluxo de execu√ß√£o em produ√ß√£o. |
| **Python-Dotenv** | **A Seguran√ßa.** Carrega segredos de ambiente. Chaves de API nunca devem estar no c√≥digo. |

---

## üß† Parte 3: Frameworks de Sistemas de IA

Aqui entram as ferramentas espec√≠ficas para construir a intelig√™ncia da aplica√ß√£o. O segredo √© saber **quando** usar cada uma.

### 1. Frameworks de Orquestra√ß√£o de LLM
*O "c√©rebro" que conecta o modelo ao c√≥digo.*

- **LangChain:** O pioneiro. Excelente para prototipagem r√°pida e integra√ß√µes amplas.
  - *Docs:* [python.langchain.com](https://python.langchain.com/)
- **LangGraph:** A evolu√ß√£o para produ√ß√£o. Focado em **grafos de estado** e loops de controle. Ideal para agentes complexos e fluxos c√≠clicos.
  - *Docs:* [langchain-ai.github.io/langgraph](https://langchain-ai.github.io/langgraph/)
- **LlamaIndex:** O especialista em dados. Focado em ingest√£o, indexa√ß√£o e estrat√©gias avan√ßadas de RAG.
  - *Docs:* [docs.llamaindex.ai](https://docs.llamaindex.ai/)

### 2. Frameworks de Agentes
*Sistemas que agem, n√£o apenas respondem.*

- **LangGraph (Agentes):** Permite construir agentes com controle granular de estado e mem√≥ria. O padr√£o para sistemas robustos.
- **CrewAI:** Focado em orquestra√ß√£o de "equipes" de agentes com pap√©is definidos (Pesquisador, Escritor). Mais alto n√≠vel.
  - *Docs:* [docs.crewai.com](https://docs.crewai.com/)
- **AutoGen (Microsoft):** Padr√£o conversacional entre m√∫ltiplos agentes. √ìtimo para simula√ß√µes complexas.
  - *Docs:* [microsoft.github.io/autogen](https://microsoft.github.io/autogen/)

### 3. Frameworks de RAG
*Conectando dados propriet√°rios.*

- **LangChain/LlamaIndex:** Ambos oferecem pipelines completos de RAG.
- **Docling:** Especialista em parsing de documentos complexos (PDFs com tabelas). Transforma arquivos em JSON/Markdown estruturado para RAG.
  - *Docs:* [ds4sd.github.io/docling](https://docling-project.github.io/docling/)

### 4. Frameworks de Modelo & Infer√™ncia
*Rodando o modelo (se voc√™ n√£o usa API propriet√°ria).*

- **Hugging Face Transformers:** A biblioteca de fato para manipular modelos open-source.
  - *Docs:* [huggingface.co/docs/transformers](https://huggingface.co/docs/transformers)
- **vLLM:** Servidor de infer√™ncia focado em alto throughput e gerenciamento de mem√≥ria (PagedAttention). Essencial para self-hosting.
  - *Docs:* [docs.vllm.ai](https://docs.vllm.ai/)
- **Unsloth:** Acelerador de Fine-Tuning. Treina modelos (Llama, Mistral) at√© 5x mais r√°pido com menos mem√≥ria.
  - *Docs:* [github.com/unslothai/unsloth](https://github.com/unslothai/unsloth)

### 5. Ecossistema de Vetores
*A mem√≥ria de longo prazo.*

- **Qdrant / Weaviate / Milvus:** Bancos vetoriais dedicados para produ√ß√£o em escala.
- **FAISS:** Biblioteca para busca vetorial local e eficiente (bom para datasets est√°ticos).

---

## üîó Parte 4: Como tudo se encaixa (Arquitetura de Refer√™ncia)

Um sistema de IA real em produ√ß√£o n√£o √© um script √∫nico. Ele √© composto por camadas especializadas trabalhando em harmonia:

1.  **Camada de Servi√ßo (FastAPI + Pydantic):** Recebe a requisi√ß√£o do usu√°rio, valida o schema de entrada e autentica.
2.  **Camada de Orquestra√ß√£o (LangGraph):** Recebe o input limpo. O grafo decide o fluxo: "Preciso buscar documentos?" ou "Posso responder direto?".
3.  **Camada de Recupera√ß√£o (Qdrant + LlamaIndex):** Se decidir buscar, consulta o Banco Vetorial usando embeddings.
4.  **Camada de Gera√ß√£o (HTTPX + LLM API):** Envia o prompt montado (contexto + pergunta) para o LLM via requisi√ß√£o ass√≠ncrona.
5.  **Camada de Observabilidade (Logging + Langfuse):** Registra cada passo (lat√™ncia, tokens usados, decis√£o do agente) para an√°lise no painel.

> **Resumo:** O AI Engineer usa Python para costurar esses componentes com robustez, transformando componentes probabil√≠sticos (LLMs) em sistemas de software confi√°veis.
