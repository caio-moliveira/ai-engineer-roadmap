# üóÑÔ∏è M√≥dulo 05: Bancos de Dados (Relacional + Vetorial)

> **Goal:** Onde a mem√≥ria e o contexto sem√¢ntico vivem.
> **Ferramentas:** `PostgreSQL`, `Vector DBs` (ex: Qdrant / Chroma / pgvector), `SQLAlchemy`.

## 1) O Novo Stack de Dados ‚Äî Dois ‚Äúc√©rebros‚Äù fundamentais

Aplica√ß√µes de IA modernas geralmente combinam:

1. **Exato (SQL)** ‚Äî Responder a consultas precisas (ex: ‚ÄúQuem √© o cliente X?‚Äù) usando bancos como **PostgreSQL**.
2. **Sem√¢ntico (Vector)** ‚Äî Responder a consultas por significado/conte√∫do (ex: ‚ÄúQuais documentos falam sobre contrato jur√≠dico?‚Äù) usando bancos vetoriais modernos.

Isso permite construir sistemas *Retrieval-Augmented Generation (RAG)* confi√°veis e escal√°veis.

---

### üß™ Exemplo 1 ‚Äî SQL Agent com LangChain (Q&A sobre banco de dados)

**O que ele faz:** Usa um agente para interpretar uma pergunta em linguagem natural, gerar uma query SQL e retornar resultados diretamente do banco.
Esse padr√£o √© √∫til para **interfaces conversacionais que respondem usando dados estruturados existentes**.

üí° No LangChain, esse fluxo √© suportado por m√≥dulos como **SQLDatabaseToolkit** e agentes que orquestram chamadas do LLM para gerar e executar SQL de forma interativa. ([LangChain Docs][1])

**Conceito de uso (sem c√≥digo execut√°vel):**

```python
# Conceitual
from langchain.sql_database import SQLDatabase
from langchain.agents import create_agent
from langchain.llms import OpenAI

# 1) Conecte ao banco de dados relacional
db = SQLDatabase.from_uri("postgresql+asyncpg://user:pass@host/dbname")

# 2) Crie um LLM com suporte para tool-calling
llm = OpenAI(...)

# 3) Crie um agente que entenda consultas em linguagem natural
agent = create_agent(model=llm, tools=[db])

# 4) O agente transforma perguntas em SQL internamente
response = agent.run("Quais clientes compraram mais de 5 produtos este m√™s?")

print(response)
```

Nesse padr√£o:

* O agente **analisa a pergunta em NL**.
* Converte em **SQL usando contexto do schema**.
* Executa no banco e retorna resultados interpretados. ([LangChain Docs][1])

Esse tipo de agente √© poderoso para **interfaces de BI conversacional ou ferramentas de auto-atendimento de dados**.

---

### üß™ Exemplo 2 ‚Äî Busca sem√¢ntica simples com LangChain

**O que ele faz:** Inkjetia um pipeline b√°sico de busca sem√¢ntica usando:

* embeddings (vetores)
* um vetor store
* um m√©todo de semelhan√ßa

Esse padr√£o √© t√≠pico de um *mini-RAG* onde voc√™ indexa textos com embeddings e recupera os documentos mais relevantes.

üí° A documenta√ß√£o do LangChain explica esse pipeline como base de um ‚Äúsemantic search engine‚Äù. ([LangChain Docs][2])

**Conceito de uso (snippet explicativo):**

```python
# Conceitual
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.llms import OpenAI

# 1) Crie embeddings para seus textos
embeddings = OpenAIEmbeddings()

# 2) Armazene no vector store
vector_store = Chroma.from_texts(
    ["Contrato de aluguel 2024", "Acordo jur√≠dico recente", "..."],
    embeddings
)

# 3) Fa√ßa uma busca sem√¢ntica
results = vector_store.similarity_search("Acordo legal atual", k=3)

for doc in results:
    print(doc.page_content)
```

Nesse fluxo:

* Cada texto vira um vetor usando um modelo de embeddings.
* O vector store faz a **busca por similaridade sem√¢ntica**.
* Retorna os documentos mais relevantes para a query. ([LangChain Docs][2])

Esse padr√£o √© a base de muitas aplica√ß√µes RAG: voc√™ primeiro encontra contexto sem√¢ntico relevante e depois fornece isso ao LLM para gerar respostas ou sumariza√ß√µes.

---

## 2) SQL n√£o Morreu

Bancos relacionais continuam sendo **o n√∫cleo da maioria das aplica√ß√µes empresariais**:

* **Integridade de dados**, transa√ß√µes ACID e joins complexos
* **Filtragem estruturada eficiente** (ex: data, status, categoria)
* Integra√ß√£o com ORMs Python modernos como **SQLAlchemy (async)** e ferramentas de migra√ß√£o como **Alembic**

Com PostgreSQL, voc√™ pode at√© combinar dados estruturados com vetores usando extens√µes como **pgvector**, reduzindo *moving parts* na arquitetura.

---

## 3) O que √© um Vector Database?

Um **vector database** √© um banco especializado para armazenar e consultar **vetores de alta dimensionalidade** (embeddings), permitindo **busca por similaridade** ao inv√©s de correspond√™ncia exata. ([Medium][3])

**Conceitos t√©cnicos:**

* **Embeddings:** vetores densos representando significado sem√¢ntico
* **ANN (Approx. Nearest Neighbor):** algoritmos como HNSW otimizam buscas
* **M√©tricas de dist√¢ncia:** Cosine similarity, inner-product e Euclidean

Vector DBs s√£o fundamentais para RAG, mem√≥ria conversacional e busca sem√¢ntica de alta performance.

---

## 4) Principais Vector Databases

Veja a se√ß√£o anterior para tabela completa com links de documenta√ß√£o.

---

## 5) PostgreSQL + pgvector ‚Äî o melhor dos dois mundos

Use PostgreSQL com extens√£o **pgvector** para armazenar vetores ao lado de metadados estruturados, permitindo filtros simult√¢neos e pesquisa sem√¢ntica com SQL. Isso simplifica arquitetura e opera√ß√µes. (Links de docs foram listados acima)

---

## 6) Padr√£o RAG: Hybrid Search e Reciprocal Rank Fusion (RRF)

Combinar vetores + busca keyword/exata resulta em mecanismos de recupera√ß√£o muito mais robustos. A t√©cnica de **RRF** (Reciprocal Rank Fusion) une m√∫ltiplos rankings em um s√≥, melhorando recall e precis√£o em buscas complexas.

---

## 7) Conectando tudo ‚Äî arquitetura t√≠pica de RAG

Um pipeline moderno pode combinar:

```
User Query
   ‚Üì
Embedding Model
   ‚Üì
Vector DB
   ‚Üì
Hybrid Results (vetorial + SQL)
   ‚Üì
LLM para gera√ß√£o com contexto
```

Componentes t√≠picos:

* **FastAPI** para APIs
* **Vector store** para sem√¢ntica
* **SQL (PostgreSQL)** para filtros/metadata
* **Retrievers RAG** para pipeline

---

## 8) Por que isso importa?

Arquiteturas que combinam **SQL + sem√¢ntica vetorial** s√£o a base de sistemas de IA escal√°veis, precisos e confi√°veis em produ√ß√£o.

---

## 9) Refer√™ncias de documenta√ß√£o

* **LangChain SQL Agent docs:** [https://docs.langchain.com/oss/python/langchain/sql-agent](https://docs.langchain.com/oss/python/langchain/sql-agent) ([LangChain Docs][1])
* **LangChain semantic search (knowledge base):** [https://docs.langchain.com/oss/python/langchain/knowledge-base](https://docs.langchain.com/oss/python/langchain/knowledge-base) ([LangChain Docs][2])
* **LangChain agents:** [https://docs.langchain.com/oss/python/langchain/agents](https://docs.langchain.com/oss/python/langchain/agents) ([LangChain Docs][4])

---

Se quiser, posso agora gerar **um exemplo completo de c√≥digo execut√°vel**, combinando:

* FastAPI
* PostgreSQL + pgvector
* Qdrant ou Chroma
* Pipeline RAG completo com LangChain

S√≥ me diga o **stack de vector DB que quer usar** (Qdrant, Chroma ou outro).

[1]: https://docs.langchain.com/oss/python/langchain/sql-agent?utm_source=chatgpt.com "Build a SQL agent - Docs by LangChain"
[2]: https://docs.langchain.com/oss/python/langchain/knowledge-base?utm_source=chatgpt.com "Build a semantic search engine with LangChain"
[3]: https://medium.com/%40vineetchachondia/langchain-basics-part-4-vector-databases-deep-dive-where-your-knowledge-actually-lives-45fd58d7f8a2?utm_source=chatgpt.com "LangChain Basics Part 4 ‚Äî Vector Databases Deep Dive"
[4]: https://docs.langchain.com/oss/python/langchain/agents?utm_source=chatgpt.com "Agents - Docs by LangChain"
