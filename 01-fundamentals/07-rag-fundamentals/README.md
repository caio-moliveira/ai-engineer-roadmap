# üîç M√≥dulo 07: RAG (Retrieval‚ÄëAugmented Generation)

> **Goal:** O ‚ÄúHello World‚Äù da IA moderna. Conectar o LLM aos seus dados com **engenharia**, n√£o com m√°gica.
>
> **RAG** √© o padr√£o dominante para IA corporativa porque permite **atualizar conhecimento sem re‚Äëtreinar modelos**, com rastreabilidade, controle e custo previs√≠vel.

---

## üß† 0) Mental model correto

**LLMs n√£o t√™m mem√≥ria persistente.**
Eles s√≥ conseguem ‚Äúver‚Äù o que est√° no **context window** naquele momento.

RAG √© a t√©cnica de:

1. **Buscar** informa√ß√£o relevante em uma base externa (seus dados)
2. **Injetar** essa informa√ß√£o no prompt
3. **Gerar** uma resposta fundamentada nesse contexto

> **RAG = Retrieval (busca) + Augmentation (contexto) + Generation (resposta)**

O AI Engineer trabalha para maximizar:

* **Recall** (trazer tudo que importa)
* **Precision** (n√£o trazer lixo)
* **Faithfulness / Grounding** (n√£o inventar)
* **Latency e custo** (ser r√°pido e sustent√°vel)

---

# 1) Por que RAG?

## 1.1 Fine‚Äëtuning vs RAG (decis√£o de engenheiro)

**Fine‚Äëtuning**:

* caro
* lento para atualizar
* dif√≠cil de auditar
* pode ‚Äúmemorizar‚Äù padr√µes indesejados

**RAG**:

* atualiza conhecimento na ingest√£o
* mant√©m o modelo gen√©rico
* adiciona rastreabilidade (cita√ß√µes)
* reduz risco de alucina√ß√£o (se bem feito)

**Regra pr√°tica:**

* Se o conhecimento muda com frequ√™ncia ‚Üí RAG
* Se o objetivo √© estilo/forma muito repetitiva ‚Üí possivelmente fine‚Äëtuning

---

# 2) O Pipeline de RAG (Etapas Cr√≠ticas)

RAG em produ√ß√£o √© um pipeline com **duas fases**:

1. **Offline (Indexing / Ingestion)** ‚Äî preparar e indexar conte√∫do
2. **Online (Retrieval + Generation)** ‚Äî atender consultas em tempo real

A maioria dos problemas de RAG n√£o est√° no LLM.
Est√° em:

* ingest√£o ruim
* chunking ruim
* recupera√ß√£o ruim
* ranking ruim
* contexto mal montado

---

## 2.1 Ingestion (Indexing) ‚Äî ‚ÄúTransformar dados em conhecimento recuper√°vel‚Äù

**Ingestion** √© o processo de pegar dados brutos (PDFs, p√°ginas, bancos, e‚Äëmails, Notion, etc.) e convert√™‚Äëlos em uma base consult√°vel.

### O que a ingest√£o realmente inclui

1. **Aquisi√ß√£o (connectors)**

   * PDF / DOCX / HTML / Notion / Confluence / SharePoint / SQL
   * Escolha dos conectores e permiss√µes

2. **Extra√ß√£o de texto e estrutura**

   * PDFs podem ser:

     * *digitais* (texto extra√≠vel)
     * *escaneados* (precisam de OCR)
   * Preservar estrutura importa: t√≠tulos, se√ß√µes, tabelas, p√°ginas

3. **Limpeza e normaliza√ß√£o**

   * remover headers/footers repetidos
   * corrigir hifeniza√ß√£o de PDF
   * padronizar whitespace
   * remover lixo (sum√°rios duplicados, p√°ginas vazias)

4. **Enriquecimento (metadata)**

   * Este √© um dos maiores diferenciais de RAG bom.
   * Exemplos de metadados √∫teis:

     * `source` (sistema/arquivo)
     * `doc_id`
     * `title`
     * `section`
     * `page`
     * `created_at`
     * `jurisdiction` / `tema` / `categoria`
     * `access_level` (controle de acesso)

5. **Deduplica√ß√£o e versionamento**

   * mesma norma em 5 PDFs diferentes
   * vers√µes de documento
   * hash de conte√∫do para detectar altera√ß√µes

6. **Chunking (quebra em unidades recuper√°veis)**

7. **Embedding + Upsert** no vector DB

> Em produ√ß√£o, ‚Äúingestion‚Äù √© um pipeline de dados de verdade.

### Erros comuns na ingest√£o

* Indexar documento inteiro como 1 chunk
* N√£o guardar metadados (perde filtro e rastreio)
* N√£o tratar OCR (texto ruim = embedding ruim)
* N√£o versionar documentos (respostas inconsistentes)

---

## 2.2 Chunking ‚Äî ‚ÄúA unidade fundamental de recupera√ß√£o‚Äù

**Chunking** √© a decis√£o mais importante do RAG.

> O retriever s√≥ consegue recuperar o que voc√™ quebrou.

Se o chunk √©:

* pequeno demais ‚Üí perde contexto, aumenta ru√≠do, aumenta custo
* grande demais ‚Üí mistura assuntos, piora precis√£o, estoura contexto

### Tamanho (e por que tokens importam)

Chunk size deve ser pensado em **tokens**, n√£o caracteres.

Regra pr√°tica inicial (texto):

* **300‚Äì800 tokens** por chunk
* **overlap 10‚Äì20%** (ou 50‚Äì150 tokens)

Mas isso varia por:

* dom√≠nio (jur√≠dico tende a precisar mais contexto)
* estilo do texto (tabelas, leis, manuais)
* estrat√©gia de s√≠ntese do LLM

---

### Overlap (por que existe)

Overlap evita que uma ideia ‚Äúcorte no meio‚Äù e fique incompleta.

Exemplo:

* par√°grafo termina no chunk 1
* continua√ß√£o no chunk 2

Com overlap, chunk 2 come√ßa um pouco antes, preservando continuidade.

---

## 2.3 Embeddings ‚Äî ‚ÄúO espa√ßo sem√¢ntico‚Äù

**Embedding** √© transformar texto (ou imagem) em um vetor num√©rico.

Esse vetor captura similaridade sem√¢ntica:

* textos sobre o mesmo assunto ficam pr√≥ximos
* termos diferentes com mesmo significado ficam pr√≥ximos

### Conceitos essenciais

* **Dimens√£o**: tamanho do vetor (ex.: 768, 1024, 1536, 3072)
* **Dist√¢ncia / Similaridade**:

  * cosine similarity (muito comum)
  * dot product
  * L2

### Escolha do embedding model (crit√©rio de engenharia)

1. **Dom√≠nio**: jur√≠dico ‚â† suporte t√©cnico ‚â† c√≥digo
2. **Idioma**: modelos que funcionam bem em PT‚ÄëBR
3. **Custo e lat√™ncia**: embedding √© chamado em lote na ingest√£o
4. **Recall vs precis√£o**: alguns modelos s√£o melhores para recupera√ß√£o

### Erros comuns

* Embedding de texto sujo (OCR ruim)
* Misturar estilos (tabelas + texto corrido) sem estrat√©gia
* Re‚Äëembed sem versionamento ‚Üí incoer√™ncia

---

## 2.4 Retrieval ‚Äî ‚ÄúEncontrar o que importa‚Äù

Retrieval √© a etapa online que escolhe quais chunks ser√£o enviados ao LLM.

### Tipos de retrieval

1. **Dense retrieval (vector search)**

   * consulta vira vetor
   * retorna chunks mais pr√≥ximos

2. **Sparse retrieval (keyword / BM25)**

   * baseado em termos exatos
   * √≥timo para n√∫meros, c√≥digos, nomes pr√≥prios

3. **Hybrid retrieval**

   * combina dense + sparse
   * √© o padr√£o em muitos cen√°rios corporativos

> A busca perfeita quase sempre √© h√≠brida.

---

### k (top‚Äëk) e o trade‚Äëoff

* k pequeno ‚Üí pode perder contexto (low recall)
* k grande ‚Üí envia muito lixo (low precision), aumenta custo

Regra inicial:

* `k = 4‚Äì10` para muitos casos
* depois ajustar com avalia√ß√£o

---

### Metadata filtering (por que SQL + metadata salva sistemas)

Filtros estruturados reduzem ru√≠do:

* per√≠odo
* tipo de documento
* status
* categoria
* munic√≠pio
* √≥rg√£o

Em produ√ß√£o, retrieval sem filtro vira:

* custo alto
* resposta inconsistente
* baixa precis√£o

---

## 2.5 Ranking e Re‚Äëranking ‚Äî ‚ÄúN√£o basta recuperar, tem que ordenar‚Äù

Vector search retorna candidatos.
Mas ordem inicial pode ser fraca.

**Re‚Äëranking** melhora a qualidade final:

* Cross‚Äëencoder rerankers
* LLM‚Äëas‚Äëreranker

Fluxo:

1. recuperar top‚Äëk grande (ex.: 30)
2. rerankar e reduzir (ex.: 8)

Isso aumenta precis√£o sem perder recall.

---

## 2.6 Synthesis / Generation ‚Äî ‚ÄúMontar contexto e responder‚Äù

Aqui o LLM entra.

Mas a chave n√£o √© ‚Äúresponder bonito‚Äù.

√â:

* **responder com base apenas no contexto**
* citar fontes
* declarar desconhecimento

A montagem do contexto importa:

* ordenar chunks por relev√¢ncia e/ou estrutura
* remover duplicados
* limitar tamanho
* incluir metadados (t√≠tulo, se√ß√£o, p√°gina)

---

# 3) Chunking Strategies (com profundidade)

Chunking √© onde a maioria dos RAGs falha.

A seguir, estrat√©gias relevantes e quando usar.

---

## 3.1 Fixed Size (baseline)

**Como funciona:** corta a cada N caracteres/tokens.

‚úÖ pr√≥s:

* simples
* r√°pido

‚ùå contras:

* quebra ideias no meio
* mistura se√ß√µes
* ruim para documentos estruturados

Use apenas como baseline.

---

## 3.2 Recursive / Text Splitters (pr√°tico e s√≥lido)

**Como funciona:** tenta dividir respeitando separadores:

* \n\n
* \n
* frases
* palavras

√â o padr√£o de muitos frameworks.

‚úÖ bom para:

* textos corridos
* docs semi‚Äëestruturados

‚ùå ainda falha em:

* tabelas
* PDFs com estrutura quebrada

---

## 3.3 Markdown / Header‚Äëbased chunking (muito bom para docs estruturados)

**Como funciona:** quebra por:

* t√≠tulos
* headers
* se√ß√µes

‚úÖ excelente para:

* documenta√ß√£o t√©cnica
* wikis
* Notion/Confluence

Porque preserva o ‚Äúmapa mental‚Äù do texto.

---

## 3.4 Semantic chunking (state of the art, mas exige cuidado)

**Como funciona:** detecta mudan√ßa de assunto usando embeddings ou heur√≠sticas sem√¢nticas.

‚úÖ pr√≥s:

* chunks mais coerentes
* melhor grounding

‚ùå contras:

* mais caro
* mais lento
* depende de texto bem extra√≠do

√ìtimo para:

* documentos longos
* textos com t√≥picos bem definidos

---

## 3.5 Sliding window + overlap (padr√£o robusto)

Combina:

* chunk size em tokens
* overlap calculado

√â um dos melhores pontos de equil√≠brio para iniciar.

---

## 3.6 Domain‚Äëaware chunking (n√≠vel expert)

Em dom√≠nios como jur√≠dico, voc√™ pode chunkar por:

* artigo
* inciso
* par√°grafo
* ementa

Isso aumenta rastreabilidade e precis√£o.

Exige:

* parsing
* estrutura confi√°vel

Mas o ganho √© enorme.

---

# 4) Grounding ‚Äî Como reduzir alucina√ß√£o

RAG s√≥ funciona bem com **grounding**.

### T√©cnicas essenciais

1. **Instru√ß√£o expl√≠cita**

   * ‚ÄúSe n√£o estiver no contexto, diga que n√£o sabe.‚Äù

2. **Cita√ß√µes e rastreabilidade**

   * cada afirma√ß√£o deve apontar para um chunk

3. **Context delimiters**

   * separar claramente o que √© contexto vs conversa

4. **Answerability checks**

   * classificar se a pergunta √© respond√≠vel

5. **Self‚Äëconsistency / verification**

   * validar resposta contra o contexto

> Empresas n√£o t√™m medo de IA.
> Elas t√™m medo de respostas inventadas.

---

# 5) Failure modes (onde RAG quebra)

* **Bad ingestion** ‚Üí texto incompleto, OCR ruim
* **Bad chunking** ‚Üí contexto quebrado
* **Bad embeddings** ‚Üí espa√ßo sem√¢ntico fraco
* **Bad retrieval** ‚Üí top‚Äëk errado
* **No reranking** ‚Üí ru√≠do alto
* **No filtering** ‚Üí custo explode
* **No grounding** ‚Üí alucina√ß√£o

---

# 6) Checklist m√≠nimo de um RAG de produ√ß√£o

* [ ] Pipeline de ingest√£o versionado
* [ ] Metadados ricos e filtr√°veis
* [ ] Chunk size em tokens + overlap
* [ ] Hybrid search quando necess√°rio
* [ ] Reranking (ao menos em casos cr√≠ticos)
* [ ] Prompt com grounding e cita√ß√µes
* [ ] M√©tricas e avalia√ß√£o (m√≥dulo 09)

---

## ‚è≠Ô∏è Pr√≥ximo passo

RAG sem avalia√ß√£o √© f√©.

V√° para **[M√≥dulo 09: Observabilidade & Avalia√ß√£o de IA](../09-observability)**.
