# üîç M√≥dulo 07: RAG (Retrieval-Augmented Generation)

> **Goal:** O "Hello World" da IA moderna. Conectar o LLM aos seus dados.
> **Ferramentas:** `LangChain`, `LlamaIndex` (Conceitos), `Vector DB`.

## 1. Por que RAG?
Fine-tuning √© caro e dif√≠cil de manter atualizado. RAG √© √°gil.
Voc√™ injeta o conhecimento no **Context Window** no momento da infer√™ncia.

## 2. O Pipeline de RAG (Etapas Cr√≠ticas)
RAG n√£o √© m√°gica, √© um pipeline de engenharia de dados.

1.  **Ingestion:** Ler PDFs, Notion, SQL.
2.  **Chunking:** Quebrar o texto. *Estrat√©gia importa:* Senten√ßa? Par√°grafo? Markdown header?
3.  **Embedding:** Transformar texto em vetor.
4.  **Retrieval:** Buscar os N chunks mais similares.
5.  **Synthesis:** LLM gera a resposta baseada APENAS no contexto recuperado.

## 3. Chunking Strategies
- **Fixed Size:** Cortar a cada 500 caracteres (Ruim, quebra contexto).
- **Recursive Character:** Tenta manter par√°grafos juntos (Padr√£o LangChain).
- **Sem√¢ntico:** Quebra quando o assunto muda (State of the Art).

## 4. Grounding (Evitando Alucina√ß√£o)
O maior medo das empresas.
- Force o modelo a responder: "Se a informa√ß√£o n√£o estiver no contexto, diga 'n√£o sei'."
- Citar fontes: O modelo deve indicar de qual chunk tirou a informa√ß√£o.

## ‚è≠Ô∏è Pr√≥ximo Passo
Como sabemos se o RAG est√° bom? "Achei a resposta boa" n√£o √© m√©trica de engenharia.
V√° para **[M√≥dulo 09: Observabilidade & Avalia√ß√£o de IA](../09-observability)**.
