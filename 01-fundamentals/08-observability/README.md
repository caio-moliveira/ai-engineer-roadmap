# üî≠ M√≥dulo 08: Observabilidade & Avalia√ß√£o de IA

> **Goal:** "Voc√™ n√£o pode melhorar o que n√£o pode medir."
> **Ferramentas:** `LangSmith`, `Arize Phoenix`, `OpenTelemetry`.

## 1. O Problema da Caixa Preta
Em software tradicional, se der erro 500, temos stack trace.
Em IA, o modelo responde "A capital da Fran√ßa √© Londres" com status 200 OK.
Isso √© um **Silent Failure**.

## 2. Tracing (Raio-X da Execu√ß√£o)
Logs lineares n√£o funcionam para cadeias de IA (Chains/Agents).
Precisamos de **Tracing Distribu√≠do**.
- Qual passo demorou mais? Retrieval ou Generation?
- Qual foi o prompt exato que causou o erro?
- Quantos tokens foram gastos nessa request?

*Ferramentas obrigat√≥rias:* LangSmith, Langfuse ou Arize Phoenix.

## 3. Evals (Unit Tests para IA)
Esque√ßa assert `result == "expected"`. LLMs s√£o n√£o-determin√≠sticos.
Usamos **LLM-as-a-Judge**.
Um LLM mais forte (GPT-4) avalia a resposta do seu sistema.

**Dataset de Ouro (Golden Dataset):**
- Input: "Como reseto minha senha?"
- Resposta Esperada: "Acesse config > seguran√ßa."
- M√©trica: A resposta gerada √© semanticamente similar √† esperada?

## 4. M√©tricas de RAG (RAGas)
- **Context Precision:** O retrieval trouxe lixo ou ouro?
- **Answer Faithfulness:** O modelo inventou algo que n√£o estava no contexto?

## ‚è≠Ô∏è Pr√≥ximo Passo
Seu sistema funciona na sua m√°quina. E agora?
V√° para **[M√≥dulo 10: Deploy, Infra e Produ√ß√£o](../10-deploy-production)**.
