# üî≠ M√≥dulo 08: Observabilidade & Avalia√ß√£o de IA

> **Goal:** "Voc√™ n√£o pode melhorar o que n√£o pode medir."
>
> Este m√≥dulo define o que separa **demos de IA** de **sistemas de IA confi√°veis em produ√ß√£o**.

Observabilidade n√£o √© opcional em IA.
Ela √© **infraestrutura cr√≠tica**.

---

## üß† Mental model correto

Em software tradicional:

* erro ‚Üí exception
* stack trace ‚Üí causa raiz

Em sistemas com LLMs:

* a resposta pode estar **errada, incoerente ou inventada**
* e ainda assim retornar **HTTP 200 OK**

Isso cria um novo tipo de falha:

> ‚ùó **Silent Failure** ‚Äî o sistema funciona tecnicamente, mas falha semanticamente.

Sem observabilidade, voc√™ nunca saber√°:

* por que a resposta ficou ruim
* quando o sistema come√ßou a degradar
* qual mudan√ßa piorou o comportamento

AI Engineers n√£o depuram apenas c√≥digo.
Eles depuram **comportamento probabil√≠stico**.

---

# 1Ô∏è‚É£ O que significa observabilidade em IA

Observabilidade em IA responde a perguntas como:

* Qual prompt foi usado?
* Qual vers√£o do prompt?
* Qual modelo?
* Quantos tokens?
* Qual custo?
* Qual contexto foi recuperado?
* Quais documentos influenciaram a resposta?
* Onde a lat√™ncia aconteceu?

Logs tradicionais n√£o conseguem responder isso.

Precisamos de **observabilidade sem√¢ntica**.

---

# 2Ô∏è‚É£ Os tr√™s pilares da observabilidade em IA

Todo sistema de IA bem observado mede:

1. **Tracing** ‚Äî o caminho da execu√ß√£o
2. **Metrics** ‚Äî custo, lat√™ncia, volume
3. **Evaluation** ‚Äî qualidade sem√¢ntica

Esses tr√™s pilares se complementam.

---

# 3Ô∏è‚É£ Tracing ‚Äî o raio-X do sistema

Tracing permite visualizar toda a execu√ß√£o de uma requisi√ß√£o:

```
User Query
   ‚Üì
Prompt Construction
   ‚Üì
Retrieval
   ‚Üì
Reranking
   ‚Üì
LLM Call
   ‚Üì
Post-processing
```

Cada etapa gera:

* tempo
* inputs
* outputs
* tokens
* erros

Isso √© essencial para depurar chains, graphs e agentes.

---

## 3.1 Por que logs tradicionais n√£o funcionam

Logs s√£o lineares.

IA √©:

* paralela
* condicional
* n√£o determin√≠stica

Um agente pode:

* chamar ferramentas
* decidir caminhos
* repetir etapas

Sem tracing estruturado, voc√™ fica cego.

---

# 4Ô∏è‚É£ Ferramentas foco do m√≥dulo

Neste roadmap, focamos em **tr√™s ferramentas fundamentais**, amplamente utilizadas em produ√ß√£o:

* **MLflow** ‚Äî tracking, versionamento e avalia√ß√£o
* **LangSmith** ‚Äî tracing e avalia√ß√£o nativa para LangChain/LangGraph
* **Langfuse** ‚Äî observabilidade completa independente de framework

Cada uma cobre uma camada diferente do problema.

---

# 5Ô∏è‚É£ MLflow ‚Äî o backbone de experimenta√ß√£o e versionamento

## O que √© MLflow

MLflow nasceu no mundo de ML tradicional, mas evoluiu para suportar **GenAI workflows**.

Ele atua como:

* sistema de tracking
* reposit√≥rio de experimentos
* versionador de artefatos

Em IA moderna, MLflow √© usado para:

* versionar prompts
* versionar datasets
* versionar embeddings
* registrar m√©tricas de avalia√ß√£o

---

## O que MLflow resolve bem

* Comparar vers√µes de prompts
* Comparar estrat√©gias de RAG
* Armazenar datasets de avalia√ß√£o
* Registrar m√©tricas automaticamente

MLflow traz **disciplina cient√≠fica** para sistemas probabil√≠sticos.

---

## Limita√ß√µes do MLflow

* N√£o √© √≥timo para tracing de chains complexas
* N√£o √© focado em runtime observability

Por isso, ele costuma ser combinado com LangSmith ou Langfuse.

---

# 6Ô∏è‚É£ LangSmith ‚Äî observabilidade nativa para LangChain

## O que √© LangSmith

LangSmith √© a ferramenta oficial de observabilidade do ecossistema LangChain.

Ele oferece:

* tracing autom√°tico
* visualiza√ß√£o de chains e graphs
* inspe√ß√£o de prompts
* logs de retrieval
* an√°lise de tokens

√â extremamente poderoso quando voc√™ usa:

* LangChain
* LangGraph

---

## O que o LangSmith permite ver

Para cada request:

* prompt final enviado ao modelo
* documentos recuperados
* ordem dos passos
* lat√™ncia por n√≥
* custo aproximado

Isso transforma debugging de IA em algo poss√≠vel.

---

## Avalia√ß√µes no LangSmith

LangSmith permite:

* datasets de avalia√ß√£o
* execu√ß√µes autom√°ticas
* LLM-as-a-Judge

Voc√™ pode comparar:

* vers√£o A vs vers√£o B
* prompt antigo vs novo
* estrat√©gia de retrieval

Tudo com hist√≥rico.

---

## Limita√ß√µes do LangSmith

* Fortemente acoplado ao LangChain
* Menos flex√≠vel fora desse ecossistema

---

# 7Ô∏è‚É£ Langfuse ‚Äî observabilidade independente de framework

## O que √© Langfuse

Langfuse √© uma plataforma de **observabilidade e avalia√ß√£o vendor-agnostic**.

Ela funciona com:

* LangChain
* LangGraph
* LlamaIndex
* APIs pr√≥prias
* chamadas diretas a LLMs

Isso a torna ideal para ambientes corporativos.

---

## Principais capacidades

* tracing distribu√≠do
* versionamento de prompts
* m√©tricas de custo
* feedback humano
* avalia√ß√£o autom√°tica
* dashboards operacionais

Langfuse trata IA como um sistema vivo.

---

## Conceito importante: Prompt como artefato

Em Langfuse:

* prompts s√£o versionados
* mudan√ßas s√£o rastreadas
* impactos s√£o medidos

Isso √© essencial para governan√ßa.

---

# 8Ô∏è‚É£ Avalia√ß√£o de IA ‚Äî o cora√ß√£o da melhoria cont√≠nua

Sem avalia√ß√£o, voc√™ n√£o evolui.

Mas IA n√£o permite asserts tradicionais.

---

## 8.1 Golden Dataset

Um **Golden Dataset** cont√©m:

* pergunta
* contexto esperado
* resposta esperada (ou diretrizes)

Ele representa casos reais do neg√≥cio.

Esse dataset deve ser:

* pequeno
* curado
* representativo

---

## 8.2 LLM-as-a-Judge

Em vez de comparar texto exato, usamos um modelo forte para avaliar:

* corre√ß√£o
* completude
* fidelidade
* utilidade

O avaliador n√£o √© o mesmo modelo do sistema.

Isso reduz vi√©s.

---

## 8.3 M√©tricas comuns

* Answer relevance
* Faithfulness
* Groundedness
* Context utilization
* Helpfulness

Essas m√©tricas permitem compara√ß√£o estat√≠stica entre vers√µes.

---

# 9Ô∏è‚É£ M√©tricas espec√≠ficas de RAG

RAG adiciona uma camada cr√≠tica: retrieval.

Principais m√©tricas:

* **Context Precision** ‚Äî quanto do contexto √© realmente √∫til
* **Context Recall** ‚Äî o que deveria ter sido recuperado
* **Answer Faithfulness** ‚Äî se a resposta usa apenas o contexto
* **Answer Relevance** ‚Äî se responde a pergunta

Sem medir retrieval, voc√™ nunca sabe se o problema est√° no LLM ou na busca.

---

# üîü Observabilidade como sistema nervoso

Observabilidade n√£o √© dashboard bonito.

Ela √© o **sistema nervoso central** do sistema de IA.

Ela permite:

* detectar degrada√ß√£o
* medir impacto de mudan√ßas
* controlar custos
* justificar decis√µes t√©cnicas

Sem isso, IA vira supersti√ß√£o.

---

# ‚úÖ Checklist m√≠nimo de produ√ß√£o

* [ ] tracing ativo
* [ ] prompts versionados
* [ ] tokens monitorados
* [ ] custo por request conhecido
* [ ] datasets de avalia√ß√£o
* [ ] LLM-as-a-judge
* [ ] compara√ß√£o entre vers√µes

---

## ‚è≠Ô∏è Pr√≥ximo passo

Seu sistema funciona.
Agora ele precisa rodar para milh√µes de usu√°rios.

V√° para **[M√≥dulo 10: Deploy, Infra e Produ√ß√£o](../10-deploy-production)**.
