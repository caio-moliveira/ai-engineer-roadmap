# ü§ñ M√≥dulo 02: Fundamentos de LLMs & GenAI

> **Objetivo:** Compreender a "f√≠sica" dos Large Language Models. N√£o apenas como usar, mas como funcionam, seus limites e como orquestr√°-los em engenharia de software robusta.
> 
> **Leitura Obrigat√≥ria para:** Quem quer parar de "chutar prompts" e come√ßar a construir sistemas determin√≠sticos.

---

## üìö 1. O que √© um LLM? (Al√©m do Hype)

Um **Large Language Model (LLM)** √©, em sua ess√™ncia, um **modelador estat√≠stico de distribui√ß√£o de tokens** treinado em uma quantidade massiva de texto. A arquitetura predominante hoje √© o **Transformer** (apresentado pelo Google em 2017).

### O Conceito de "Autoregressive"
O modelo n√£o "pensa". Ele calcula a probabilidade do pr√≥ximo *token* dado o hist√≥rico anterior.
$$ P(w_t | w_{t-1}, w_{t-2}, ..., w_1) $$

Isso significa que o modelo √© **determin√≠stico** na sua distribui√ß√£o de probabilidades, mas **estoc√°stico** na sua gera√ß√£o (dependendo da temperatura).

> **Refer√™ncia Cl√°ssica:** [Attention Is All You Need (Vaswani et al., 2017)](https://arxiv.org/abs/1706.03762) - O paper que criou a arquitetura Transformer.

---

## üî† 2. Tokeniza√ß√£o: A Unidade At√¥mica

LLMs n√£o leem "palavras". Eles leem **Tokens**.
A maioria dos modelos modernos usa **BPE (Byte Pair Encoding)**.

*   **Ingl√™s:** 1 palavra $\approx$ 1.3 tokens.
*   **Portugu√™s/Outros:** Pode ser menos eficiente (mais tokens por palavra).
*   **N√∫meros:** `9.11` pode ser quebrado em `9`, `.`, `11` ou `9`, `.`, `1`, `1`. Isso explica por que LLMs erram matem√°tica simples sem ferramentas.

### Por que importa?
1.  **Custo:** Voc√™ paga por token (Input/Output).
2.  **Context Window:** O limite de "mem√≥ria" do modelo √© em tokens.
3.  **Performance:** "A strawberry tem quantos Rs?" O modelo v√™ tokens, n√£o letras. Se "strawberry" for um token √∫nico `[STRAWBERRY]`, ele n√£o "v√™" os Rs internos sem quebrar a palavra.

> **Tool:** [OpenAI Tokenizer](https://platform.openai.com/tokenizer) - Visualize como seu texto vira n√∫meros.

---

## üß† 3. Context Window & "Attention"

A **Context Window** √© a mem√≥ria de curto prazo. Tudo que n√£o est√° na janela de contexto **n√£o existe** para o modelo naquele momento.

Sim, modelos como Gemini 1.5 Pro suportam 1M+ tokens. Mas cuidado com o fen√¥meno **"Lost in the Middle"**: a performance de recupera√ß√£o (recall) tende a ser melhor no in√≠cio e no fim do prompt, e pior no meio.

> **Refer√™ncia:** [Lost in the Middle: How Language Models Use Long Contexts (Liu et al., 2023)](https://arxiv.org/abs/2307.03172)

---

## üéõÔ∏è 4. Hiperpar√¢metros de Gera√ß√£o

Voc√™ controla a "criatividade" do modelo ajustando como ele escolhe o pr√≥ximo token dessa distribui√ß√£o probabil√≠stica.

### Temperature (0.0 a 2.0)
*   **Baixa (0.0 - 0.3):** Escolhe sempre os tokens mais prov√°veis. Mais determin√≠stico, focado, bom para c√≥digo e JSON.
*   **Alta (0.7 - 1.5):** Nivela as probabilidades, permitindo que tokens menos √≥bvios sejam escolhidos. Mais criativo, mas propenso a alucina√ß√µes.

### Top-P (Nucleus Sampling)
Cortamos a cauda da distribui√ß√£o.
*   **Top-P = 0.9:** O modelo considera apenas os top tokens que somam 90% da probabilidade cumulativa. Elimina op√ß√µes absurdas.

> **Regra de Ouro:** Altere *Temperature* OU *Top-P*, geralmente n√£o os dois simultaneamente.

---

## üó£Ô∏è 5. Prompt Engineering (A Ci√™ncia, n√£o a Arte)

Engenharia de Prompt n√£o √© sobre "pedir com educa√ß√£o". √â sobre **condicionar a distribui√ß√£o probabil√≠stica** para o resultado desejado.

### 5.1 Zero-Shot vs Few-Shot
*   **Zero-Shot:** Pedir sem exemplos. "Classifique este texto."
*   **Few-Shot:** Dar exemplos input/output. √â a t√©cnica mais poderosa para melhorar performance sem treinar o modelo.
    > "Language Models are Few-Shot Learners" (GPT-3 Paper).

### 5.2 Chain-of-Thought (CoT)
Pedir para o modelo "pensar passo a passo". Isso for√ßa o modelo a gerar tokens de racioc√≠nio *antes* da resposta final, aumentando a precis√£o em tarefas l√≥gicas/matem√°ticas.
> **Refer√™ncia:** [Chain-of-Thought Prompting Elicits Reasoning in Large Language Models (Wei et al., 2022)](https://arxiv.org/abs/2201.11903)
> **Refer√™ncia:** [Prompt Engineering Guide](https://www.promptingguide.ai/)

### 5.3 System Prompts
A "constitui√ß√£o" do seu agente. Define persona, limites e formato de resposta. Sempre separe instru√ß√µes do sistema (persistentes) da entrada do usu√°rio (vari√°vel).

---

## ü§ñ 6. Tool Calling & Agentes

LLMs s√£o c√©rebros "presos em uma caixa". Eles n√£o t√™m rel√≥gio, n√£o acessam a internet e n√£o rodam c√≥digo.
**Tool Calling (Function Calling)** resolve isso.

1.  Voc√™ descreve uma fun√ß√£o (ex: `get_weather(city)`) em JSON Schema.
2.  O LLM, se precisar, retorna um JSON pedindo para executar essa fun√ß√£o.
3.  Seu backend executa a fun√ß√£o e devolve o resultado para o LLM.
4.  O LLM formula a resposta final.

Isso √© a base dos **Agentes**: LLMs que podem *agir* no mundo.
> **Refer√™ncia:** [ReAct: Synergizing Reasoning and Acting in Language Models (Yao et al., 2023)](https://arxiv.org/abs/2210.03629)

---

## üõ†Ô∏è 7. RAG vs Fine-Tuning

A d√∫vida cl√°ssica.

| Feature | **RAG (Retrieval-Augmented Generation)** | **Fine-Tuning** |
| :--- | :--- | :--- |
| **Conhecimento** | Externo, din√¢mico (banco vetorial). | Interno, est√°tico (pesos do modelo). |
| **Atualiza√ß√£o** | Imediata (basta inserir no DB). | Lenta (precisa re-treinar). |
| **Alucina√ß√£o** | Baixa (ancorado em documentos). | M√©dia/Alta (se n√£o souber, inventa). |
| **Uso Principal** | Dar acesso a dados privados/recentes. | Ensinar um *formato*, *estilo* ou *linguagem* nova. |

> **Veredito:** 90% dos casos de uso de "dados da minha empresa" s√£o resolvidos com RAG, n√£o Fine-Tuning.

---

## üîó Refer√™ncias Essenciais

*   [OpenAI Deep Learning (Andrej Karpathy)](https://www.youtube.com/watch?v=zjkBMFhNj_g) - Intro t√©cnica obrigat√≥ria.
*   [Anthropic's Prompt Engineering Guide](https://docs.anthropic.com/claude/docs/prompt-engineering) - Um dos melhores guias pr√°ticos.
*   [Lilian Weng Blog (OpenAI)](https://lilianweng.github.io/) - Artigos profundos sobre Agentes e LLMs.
