# üîπ Bloco 5: Fine-Tuning e Melhora de Modelo

> **Objetivo:** Saber quando treinar ‚Äî e principalmente quando N√ÉO treinar.  
> **Status:** A √∫ltima milha da especializa√ß√£o.

## üõë Pare. Leia isto.
Fine-Tuning n√£o resolve alucina√ß√£o.
Fine-Tuning n√£o adiciona conhecimento factual novo de forma confi√°vel.
Fine-Tuning n√£o √© m√°gica.

Se voc√™ est√° aqui porque "o RAG n√£o funcionou", volte para o Bloco 2.
Fine-Tuning √© para **Forma**, **Estilo**, **Comportamento** e **Efici√™ncia**, n√£o para fatos.

Este bloco vai te ensinar a responsabilidade de "tocar nos pesos" do modelo.

---

## üìö Ementa do M√≥dulo

### [M√≥dulo 1: O que √© Fine-Tuning (Realmente)](./01-finetuning-concepts)
- **Realidade:** Adapta√ß√£o de pesos vs Inje√ß√£o de Conhecimento.
- **Mito:** "Vou treinar o modelo nos meus PDFs para ele saber sobre minha empresa." (Spoiler: N√£o vai funcionar).
- **Fato:** Fine-Tuning ensina o modelo a FALAR como um m√©dico, n√£o a SER um m√©dico.

### [M√≥dulo 2: Fine-Tuning vs RAG vs Prompting](./02-rag-vs-finetuning)
- **Matriz de Decis√£o:** O framework definitivo para escolher a abordagem.
- **RAG:** Para fatos novos e din√¢micos.
- **Fine-Tuning:** Para estilo consistente e redu√ß√£o de lat√™ncia/custo.
- **Prompting:** Onde voc√™ deve gastar 90% do seu tempo inicial.

### [M√≥dulo 3: Tipos de Adapta√ß√£o](./03-adaptation-types)
- **Full Fine-Tuning:** Por que voc√™ quase nunca vai fazer isso.
- **PEFT / LoRA:** Como treinar modelos gigantes com pouco VRAM.
- **Instruction Tuning:** Ensinando o modelo a seguir ordens.
- **Likelihood Training (DPO/ORPO):** Ensinando o modelo o que voc√™ prefere.

### [M√≥dulo 4: Dados s√£o o Modelo](./04-data-prep)
- **A Verdade:** O modelo √© apenas um espelho dos seus dados.
- **Qualidade > Quantidade:** 100 exemplos perfeitos valem mais que 10.000 exemplos ruins.
- **Instruction Datasets:** Como formatar seus dados corretamente.

### [M√≥dulo 5: Avalia√ß√£o antes do Treino](./05-evaluation)
- **Regra:** Se voc√™ n√£o consegue medir, n√£o treine.
- **Baselines:** Como saber se o treino piorou o modelo (Catastrophic Forgetting).
- **LLM-as-a-Judge:** Usando GPT-4 para dar nota no seu Llama-3 finetunado.

### [M√≥dulo 6: Unsloth (Pr√°tico)](./06-unsloth)
- **A Ferramenta:** Por que Unsloth √© o padr√£o ouro hoje.
- **Efici√™ncia:** Treinando 2x mais r√°pido com 70% menos mem√≥ria.
- **Workflow:** Do notebook para o GGUF/LoRA Adapter.

### [M√≥dulo 7: Infra de Treino & Custo Real](./07-training-ops)
- **Hardware:** Quanto de VRAM voc√™ realmente precisa.
- **Spot Instances:** Economizando 70% na AWS/RunPod.
- **Custo Oculto:** O tempo de engenharia para limpar dados vs o custo de GPU.

### [M√≥dulo 8: Deploy & Infer√™ncia P√≥s-Treino](./08-deploy-adapters)
- **Adapters:** Como carregar LoRA adapters no vLLM sem duplicar o modelo base.
- **Merge:** Quando fundir os pesos (Mergekit) e quando carregar dinamicamente.
- **Drift:** Monitorando se o modelo "desaprendeu" coisas importantes.

### [M√≥dulo 9: Riscos & Manuten√ß√£o](./09-risks-maintenance)
- **Catastrophic Forgetting:** O modelo ficou √≥timo em SQL, mas esqueceu como falar ingl√™s.
- **Manuten√ß√£o:** Modelo treinado √© modelo "congelado". Como atualizar?

### [M√≥dulo 10: Enterprise & Gov](./10-enterprise-gov)
- **Compliance:** Quando o Fine-Tuning √© obrigat√≥rio por lei (On-premise total).
- **Privacidade:** Garantindo que dados sens√≠veis n√£o vazem.

---

## üõ†Ô∏è Stack de Treino (Padr√£o 2025)

| Componente | Escolha | Por qu√™? |
|:---|:---|:---|
| **Framework** | Unsloth | Velocidade e efici√™ncia de mem√≥ria imbat√≠veis. |
| **T√©cnica** | QLoRA (4-bit) | Permite treinar 70B em GPUs "baratas" (A6000/A100). |
| **Eval** | Ragas / LLM-as-Judge | Avalia√ß√£o escal√°vel antes de deploy. |
| **Dataset** | Hugging Face Datasets | Gerenciamento e versionamento de dados. |

## üß† Mudan√ßas Mentais Necess√°rias
- **Menos √© Mais:** Comece com 50 exemplos. Teste. Se melhorar, adicione mais.
- **Dados s√£o C√≥digo:** Trate seu dataset com o mesmo rigor que trata seu c√≥digo (versionamento, code review, linting).
- **Voc√™ provavelmente n√£o precisa de Fine-Tuning:** S√©rio. RAG + Few-Shot Prompting resolve 95% dos casos.

## üöÄ Como come√ßar
V√° para **[M√≥dulo 1: O que √© Fine-Tuning (Realmente)](./01-finetuning-concepts)**.
