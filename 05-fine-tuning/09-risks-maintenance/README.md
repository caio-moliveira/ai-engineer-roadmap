# ‚ö†Ô∏è M√≥dulo 9: Riscos, Falhas & Manuten√ß√£o

> **Goal:** Gerenciar o ciclo de vida.  
> **Status:** Preven√ß√£o de desastres.

## 1. Catastrophic Forgetting
Voc√™ treina o modelo para falar "Engra√ßado".
De repente, ele n√£o sabe mais programar em Python.
**Causa:** O treino alterou pesos que eram cruciais para a l√≥gica, em favor do estilo.
**Solu√ß√£o:** Adicione 10-20% de dados gerais de alta qualidade no seu dataset de treino (Dataset Replay) para "lembrar" o modelo de ser inteligente.

## 2. Data Staleness (Dados Velhos)
Se voc√™ treinou o modelo com dados de 2023.
Em 2025, o usu√°rio pergunta "Quem √© o presidente?".
O modelo responde com convic√ß√£o (porque √© Fine-Tuning) o nome errado.
**Solu√ß√£o:** NUNCA use FT para fatos temporais. Use RAG.

## 3. Feedback Loops
Se voc√™ usa dados gerados pelo modelo para treinar a pr√≥xima vers√£o do modelo...
O modelo vai colapsar (Model Collapse). As idiossincrasias se amplificam.
Sempre mantenha dados humanos ou dados de um modelo superior (Oracle) no loop.

## üß† Mental Model: "Entropia"
Modelos finetunados tendem a degradar com o tempo se n√£o forem cuidados.
A "intelig√™ncia geral" √© fr√°gil. Proteja-a.

## ‚è≠Ô∏è Pr√≥ximo Passo
Como grandes empresas fazem isso?
V√° para **[M√≥dulo 10: Fine-Tuning em Enterprise & Gov](../10-enterprise-gov)**.
