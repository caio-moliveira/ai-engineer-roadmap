# ğŸ“‰ MÃ³dulo 5: AvaliaÃ§Ã£o antes do Treino (ObrigatÃ³rio)

> **Goal:** Evitar o "Vibe Check".  
> **Status:** A diferenÃ§a entre CiÃªncia e Alquimia.

## 1. O Perigo do "OlhÃ´metro"
VocÃª treinou. VocÃª abre o chat. VocÃª pergunta "Oi". O modelo responde "OlÃ¡".
VocÃª conclui: "O modelo estÃ¡ Ã³timo!"
Narrador: "O modelo nÃ£o estava Ã³timo. Ele esqueceu como somar 2+2."

## 2. Crie o "Golden Set" (Conjunto Ouro)
Antes de sequer pensar em ligar a GPU:
1.  Separe 50 perguntas difÃ­ceis que representam seu problema real.
2.  Escreva (vocÃª mesmo, humano) as respostas perfeitas para elas.
3.  Essas 50 perguntas **NUNCA** entram no treino. Elas sÃ£o o Test Set.

## 3. MÃ©tricas AutomÃ¡ticas
NÃ£o use BLEU ou ROUGE (mÃ©tricas de traduÃ§Ã£o). Elas sÃ£o inÃºteis para a maioria dos casos de LLM.
Use **LLM-as-a-Judge**:
- PeÃ§a para o GPT-4 comparar a resposta do seu Modelo Finetunado com a resposta do Golden Set.
- DÃª uma nota de 1 a 5.

## 4. RegressÃ£o (NÃ£o piore o modelo)
Execute benchmarks gerais (MMLU, GSM8K) antes e depois.
Se o seu modelo treinado para SQL perdeu 20% de performance em LÃ³gica, vocÃª teve **Catastrophic Forgetting**.
VocÃª precisa diminuir o Learning Rate ou adicionar dados de "replay" (dados gerais misturados com dados especÃ­ficos).

## ğŸ§  Mental Model: "Unit Tests para o CÃ©rebro"
VocÃª nÃ£o faz deploy de cÃ³digo sem testes.
NÃ£o faÃ§a deploy de pesos sem evals.

## â­ï¸ PrÃ³ximo Passo
MÃ£o na massa. Vamos usar Unsloth.
VÃ¡ para **[MÃ³dulo 6: Unsloth](../06-unsloth)**.
