# üî¢ M√≥dulo 3: Embeddings

> **Goal:** Transformar texto em n√∫meros (Coordenadas Sem√¢nticas).  
> **Status:** A funda√ß√£o da Busca Sem√¢ntica.

## 1. O que √© um Embedding?
√â uma lista de n√∫meros (um vetor) que representa o "Significado" de um texto.
`[0.12, -0.98, 0.44, ...]`

- **M√°gica:** Nesse espa√ßo de 1536 dimens√µes, "Rei" - "Homem" + "Mulher" ‚âà "Rainha".
- **Sem√¢ntica:** "Cachorro" est√° mais perto de "Filhote" do que de "Gato", e mais perto de "Gato" do que de "Carro".

## 2. Escolha do Modelo (2025)
N√£o use apenas a OpenAI cegamente.

| Modelo | Provedor | Dims | Pros | Contras |
|:---|:---|:---|:---|:---|
| **text-embedding-3-small** | OpenAI | 1536 | Barato, r√°pido, padr√£o. | Privacidade, Custo em escala. |
| **text-embedding-3-large** | OpenAI | 3072 | Maior acur√°cia. | 2x custo, 2x tamanho de storage. |
| **bge-m3 / multilingual-e5** | Open Source | 1024 | Gr√°tis, roda local, bate a OpenAI. | Voc√™ precisa hospedar (GPU necess√°ria). |
| **Cohere Embed v3** | Cohere | 1024 | Especializado em RAG. | Custo de API. |

## 3. A "Maldi√ß√£o da Dimensionalidade"
- **Mais Dimens√µes** = Mais Nuance = Mais Custo de Storage ($$$) + Busca mais Lenta.
- O `text-3` da OpenAI permite **Encurtar Embeddings**. Voc√™ pode cortar o vetor de 1536 para 512 e perder apenas ~2% de acur√°cia.

## 4. M√©tricas de Dist√¢ncia
Como medimos a "proximidade"?
1.  **Cosine Similarity:** O padr√£o. Mede o √¢ngulo. (1.0 = Igual, 0 = Ortogonal, -1 = Oposto).
2.  **Dot Product:** Apenas para vetores normalizados. Mais r√°pido.
3.  **Euclidean (L2):** Mede a dist√¢ncia em linha reta. Raramente usado para texto.

## üß† Mental Model: "O Mapa da Biblioteca"
Embeddings s√£o coordenadas de GPS para os livros na biblioteca.
- Livros de "Culin√°ria" est√£o na Latitude 40.
- Livros de "Hist√≥ria" est√£o na Latitude 80.
- Uma pergunta "Melhor receita de massa" cai na Latitude 40.01.
N√≥s apenas olhamos os livros mais pr√≥ximos.

## ‚ö†Ô∏è Erros Comuns
- **Misturar Modelos:** Voc√™ N√ÉO PODE buscar um vetor `bge-m3` contra um vetor `openai`. Voc√™ deve re-indexar tudo se trocar de modelo.
- **Ignorar Multilingual:** OpenAI √© decente, mas `multilingual-e5` √© muito melhor para Portugu√™s/Espanhol.

## ‚è≠Ô∏è Pr√≥ximo Passo
Onde guardamos esses milh√µes de vetores?
V√° para **[M√≥dulo 4: Vector Databases](../04-vector-dbs)**.
