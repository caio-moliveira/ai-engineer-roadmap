# üìÑ M√≥dulo 2: Ingest√£o de Dados & Pipelines de Documentos

> **Goal:** Lixo entra, Lixo sai. Domine a arte de limpar dados.  
> **Status:** A parte mais subestimada da IA.

## 1. O Documento √© o Inimigo
PDFs s√£o feitos para impress√£o, n√£o para leitura.
- Eles t√™m cabe√ßalhos, rodap√©s, colunas m√∫ltiplas e imagens.
- Se voc√™ extrair texto cegamente, recebe: `Cabe√ßalho Pag 1 Conte√∫do Cabe√ßalho Pag 2`.
- Isso destr√≥i o significado sem√¢ntico.

### Estrat√©gias de Parsing
1.  **Text Extraction (pypdf):** R√°pido, gr√°tis, perde tabelas/layout. Use para contratos simples.
2.  **OCR (Tesseract):** Essencial para docs escaneados. Lento.
3.  **Vision Models (GPT-4o / Claude Vision):** Envia a imagem da p√°gina. Caro, mas 99% preciso.
4.  **Layout Parsing (Unstructured.io / Microsoft Azure DI):** Detecta "T√≠tulo", "Tabela", "Barra Lateral". A escolha profissional.

## 2. Filosofia de Chunking
Voc√™ n√£o pode enviar um livro de 100 p√°ginas para o modelo de embedding (contexto limitado). Voc√™ deve "fatiar" (chunk).

### Estrat√©gia A: Fixed Size (O jeito "ing√™nuo")
- Dividir a cada 500 caracteres.
- **Problema:** Corta frases no meio. Quebra contexto.

### Estrat√©gia B: Recursive Character (Padr√£o LangChain)
- Divide por Par√°grafos (`\n\n`) -> Frases (`.`) -> Palavras (` `).
- **Veredito:** Bom baseline.

### Estrat√©gia C: Semantic Chunking (Avan√ßado)
- Usa um modelo de embedding para escanear o documento.
- Inicia um novo chunk quando o *t√≥pico muda* (similaridade de cosseno cai).
- **Veredito:** Alta qualidade, indexa√ß√£o mais lenta.

### Estrat√©gia D: Hierarchical Indexing (Parent-Child)
- **Store:** A p√°gina inteira (Pai).
- **Search:** Pequenos chunks de 200 chars (Filhos).
- **Retrieval:** Se um filho √© encontrado, retorne o *Pai*.
- **Por que:** Chunks pequenos casam melhor com a busca. Chunks grandes d√£o melhor contexto pro LLM.

## 3. Extra√ß√£o de Metadados
**Se voc√™ n√£o extrai metadados, sua busca √© burra.**

Exemplo: "Qual foi a receita em 2023?"
- **Sem Metadados:** Busca em todos os docs "receita". Retorna 2021, 2022, 2024.
- **Com Metadados:** Filtra `year == 2023`.

**Como extrair?**
- Use um LLM barato (GPT-4o-mini) durante a ingest√£o para extrair JSON:
  ```json
  {
    "title": "Relat√≥rio Q3",
    "year": 2023,
    "department": "Vendas",
    "summary": "Receita subiu 20%"
  }
  ```

## 4. Arquitetura Real de Pipeline
N√£o escreva um script. Construa um pipeline.

1.  **Trigger:** Usu√°rio sobe arquivo.
2.  **Queue:** Arquivo vai para Redis/SQS.
3.  **Worker:**
    - Detecta tipo (MIME).
    - Parse (Unstructured).
    - Extrai Metadados (LLM).
    - Chunk (Recursive).
    - Embed (OpenAI).
    - Upsert (Qdrant).
4.  **Status:** Notifica Usu√°rio "Arquivo Pronto".

## üß† Mental Model: "Fragmenta√ß√£o"
Se voc√™ picotar um romance de mist√©rio aleatoriamente, pode pegar um peda√ßo que diz:
*"Ele fez isso."*
Quem √© "Ele"? O contexto foi perdido.
**Overlap** ajuda (manter 50 chars do anterior), mas **Parent-Child** √© a corre√ß√£o real.

## ‚è≠Ô∏è Pr√≥ximo Passo
Como transformamos texto em matem√°tica?
V√° para **[M√≥dulo 3: Embeddings](../03-embeddings)**.
