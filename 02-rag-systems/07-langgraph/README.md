# üß∂ M√≥dulo 7: LangGraph

> **Goal:** De Chains (DAGs) para Agentes (Loops).  
> **Status:** O futuro da orquestra√ß√£o RAG.

## 1. Por que LangGraph?
Pipelines LangChain s√£o **Directed Acyclic Graphs (DAGs)**. Input -> Passo 1 -> Passo 2 -> Output.
A vida real √© **C√≠clica**.
- "Retrieval retornou 0 resultados. Tentar buscar sin√¥nimos?" (Loop).
- "Resposta amb√≠gua. Pedir clarifica√ß√£o ao usu√°rio." (Loop).

LangGraph introduz **State Machines** (M√°quinas de Estado) para IA.

## 2. Conceitos Core
- **State:** Um dicion√°rio compartilhado (TypedDict) que persiste entre os passos.
- **Nodes:** Fun√ß√µes que modificam o estado.
- **Edges:** L√≥gica que decide para onde ir a seguir (Condicional).

## 3. A Arquitetura
```python
from langgraph.graph import StateGraph, END

# 1. Definir Estado
class AgentState(TypedDict):
    question: str
    documents: List[str]
    answer: str

# 2. Definir Nodes
def retrieve(state):
    docs = vector_db.search(state['question'])
    return {"documents": docs}

def generate(state):
    # L√≥gica para checar se docs s√£o bons...
    return {"answer": llm.invoke(...)}

# 3. Construir Grafo
workflow = StateGraph(AgentState)
workflow.add_node("retrieve", retrieve)
workflow.add_node("generate", generate)

workflow.set_entry_point("retrieve")
workflow.add_edge("retrieve", "generate")
workflow.add_edge("generate", END)

app = workflow.compile()
```

## 4. Corrective RAG (CRAG)
Um dos melhores patterns para RAG l√≥gico.
- **Node 1:** Retrieve.
- **Node 2:** Grade Documents (LLM checa se docs s√£o relevantes).
- **Edge:**
    - Se Relevante -> Generate.
    - Se Irrelevante -> **Web Search** (Fallback).

## üß† Mental Model: "M√°quina de Estados"
N√£o pense em "Chains". Pense em um Fluxograma.
- In√≠cio -> Busca -> Achamos?
    - Sim -> Resposta.
    - N√£o -> Re-frasear -> Buscar de novo.

## ‚è≠Ô∏è Pr√≥ximo Passo
Existe alternativa ao LangChain?
V√° para **[M√≥dulo 8: LlamaIndex](../08-llamaindex)**.
